{
  "title": "Retrieve Message Batch results (Ruby)",
  "content": "URL: https://platform.claude.com/docs/en/api/ruby/messages/batches/results\n\n`messages.batches.results(message_batch_id) -> MessageBatchIndividualResponse`\n\n**get** `/v1/messages/batches/{message_batch_id}/results`\n\nStreams the results of a Message Batch as a `.jsonl` file.\n\nEach line in the file is a JSON object containing the result of a single request in the Message Batch. Results are not guaranteed to be in the same order as requests. Use the `custom_id` field to match results to requests.\n\nLearn more about the Message Batches API in our [user guide](https://docs.claude.com/en/docs/build-with-claude/batch-processing)\n\n- `message_batch_id: String`\n\nID of the Message Batch.\n\n- `class MessageBatchIndividualResponse`\n\nThis is a single line in the response `.jsonl` file and does not represent the response as a whole.\n\n- `custom_id: String`\n\nDeveloper-provided ID created for each request in a Message Batch. Useful for matching results to requests, as results may be given out of request order.\n\nMust be unique for each request within the Message Batch.\n\n- `result: MessageBatchResult`\n\nProcessing result for this request.\n\nContains a Message output if processing was successful, an error response if processing failed, or the reason why processing was not attempted, such as cancellation or expiration.\n\n- `class MessageBatchSucceededResult`\n\nUnique object identifier.\n\nThe format and length of IDs may change over time.\n\n- `content: Array[ContentBlock]`\n\nContent generated by the model.\n\nThis is an array of content blocks, each of which has a `type` that determines its shape.\n\nIf the request input `messages` ended with an `assistant` turn, then the response `content` will continue directly from that last turn. You can use this to constrain the model's output.\n\nFor example, if the input `messages` were:\n\nThen the response `content` might be:\n\n- `citations: Array[TextCitation]`\n\nCitations supporting the text block.\n\nThe type of citation returned will depend on the type of document being cited. Citing a PDF results in `page_location`, plain text results in `char_location`, and content document results in `content_block_location`.\n\n- `class CitationCharLocation`\n\n- `cited_text: String`\n\n- `document_index: Integer`\n\n- `document_title: String`\n\n- `end_char_index: Integer`\n\n- `start_char_index: Integer`\n\n- `type: :char_location`\n\n- `class CitationPageLocation`\n\n- `cited_text: String`\n\n- `document_index: Integer`\n\n- `document_title: String`\n\n- `end_page_number: Integer`\n\n- `start_page_number: Integer`\n\n- `type: :page_location`\n\n- `class CitationContentBlockLocation`\n\n- `cited_text: String`\n\n- `document_index: Integer`\n\n- `document_title: String`\n\n- `end_block_index: Integer`\n\n- `start_block_index: Integer`\n\n- `type: :content_block_location`\n\n- `:content_block_location`\n\n- `class CitationsWebSearchResultLocation`\n\n- `cited_text: String`\n\n- `encrypted_index: String`\n\n- `type: :web_search_result_location`\n\n- `:web_search_result_location`\n\n- `class CitationsSearchResultLocation`\n\n- `cited_text: String`\n\n- `end_block_index: Integer`\n\n- `search_result_index: Integer`\n\n- `start_block_index: Integer`\n\n- `type: :search_result_location`\n\n- `:search_result_location`\n\n- `class ThinkingBlock`\n\n- `signature: String`\n\n- `class RedactedThinkingBlock`\n\n- `type: :redacted_thinking`\n\n- `:redacted_thinking`\n\n- `class ToolUseBlock`\n\n- `input: Hash[Symbol, untyped]`\n\n- `class ServerToolUseBlock`\n\n- `input: Hash[Symbol, untyped]`\n\n- `name: :web_search`\n\n- `type: :server_tool_use`\n\n- `class WebSearchToolResultBlock`\n\n- `content: WebSearchToolResultBlockContent`\n\n- `class WebSearchToolResultError`\n\n- `error_code: :invalid_tool_input | :unavailable | :max_uses_exceeded | 2 more`\n\n- `:invalid_tool_input`\n\n- `:max_uses_exceeded`\n\n- `:too_many_requests`\n\n- `type: :web_search_tool_result_error`\n\n- `:web_search_tool_result_error`\n\n- `Array[WebSearchResultBlock]`\n\n- `encrypted_content: String`\n\n- `type: :web_search_result`\n\n- `:web_search_result`\n\n- `tool_use_id: String`\n\n- `type: :web_search_tool_result`\n\n- `:web_search_tool_result`\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `:\"claude-opus-4-5-20251101\" | :\"claude-opus-4-5\" | :\"claude-3-7-sonnet-latest\" | 17 more`\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `:\"claude-opus-4-5-20251101\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `:\"claude-opus-4-5\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `:\"claude-3-7-sonnet-latest\"`\n\nHigh-performance model with early extended thinking\n\n- `:\"claude-3-7-sonnet-20250219\"`\n\nHigh-performance model with early extended thinking\n\n- `:\"claude-3-5-haiku-latest\"`\n\nFastest and most compact model for near-instant responsiveness\n\n- `:\"claude-3-5-haiku-20241022\"`\n\n- `:\"claude-haiku-4-5\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `:\"claude-haiku-4-5-20251001\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `:\"claude-sonnet-4-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `:\"claude-sonnet-4-0\"`\n\nHigh-performance model with extended thinking\n\n- `:\"claude-4-sonnet-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `:\"claude-sonnet-4-5\"`\n\nOur best model for real-world agents and coding\n\n- `:\"claude-sonnet-4-5-20250929\"`\n\nOur best model for real-world agents and coding\n\n- `:\"claude-opus-4-0\"`\n\nOur most capable model\n\n- `:\"claude-opus-4-20250514\"`\n\nOur most capable model\n\n- `:\"claude-4-opus-20250514\"`\n\nOur most capable model\n\n- `:\"claude-opus-4-1-20250805\"`\n\nOur most capable model\n\n- `:\"claude-3-opus-latest\"`\n\nExcels at writing and complex tasks\n\n- `:\"claude-3-opus-20240229\"`\n\nExcels at writing and complex tasks\n\n- `:\"claude-3-haiku-20240307\"`\n\nOur previous most fast and cost-effective\n\nConversational role of the generated message.\n\nThis will always be `\"assistant\"`.\n\n- `stop_reason: StopReason`\n\nThe reason that we stopped.\n\nThis may be one the following values:\n\n* `\"end_turn\"`: the model reached a natural stopping point\n          * `\"max_tokens\"`: we exceeded the requested `max_tokens` or the model's maximum\n          * `\"stop_sequence\"`: one of your provided custom `stop_sequences` was generated\n          * `\"tool_use\"`: the model invoked one or more tools\n          * `\"pause_turn\"`: we paused a long-running turn. You may provide the response back as-is in a subsequent request to let the model continue.\n          * `\"refusal\"`: when streaming classifiers intervene to handle potential policy violations\n\nIn non-streaming mode this value is always non-null. In streaming mode, it is null in the `message_start` event and non-null otherwise.\n\n- `stop_sequence: String`\n\nWhich custom stop sequence was generated, if any.\n\nThis value will be a non-null string if one of your custom stop sequences was generated.\n\nFor Messages, this is always `\"message\"`.\n\nBilling and rate-limit usage.\n\nAnthropic's API bills and rate-limits by token counts, as tokens represent the underlying cost to our systems.\n\nUnder the hood, the API transforms requests into a format suitable for the model. The model's output then goes through a parsing stage before becoming an API response. As a result, the token counts in `usage` will not match one-to-one with the exact visible content of an API request or response.\n\nFor example, `output_tokens` will be non-zero, even for an empty string response from Claude.\n\nTotal input tokens in a request is the summation of `input_tokens`, `cache_creation_input_tokens`, and `cache_read_input_tokens`.\n\n- `cache_creation: CacheCreation`\n\nBreakdown of cached tokens by TTL\n\n- `ephemeral_1h_input_tokens: Integer`\n\nThe number of input tokens used to create the 1 hour cache entry.\n\n- `ephemeral_5m_input_tokens: Integer`\n\nThe number of input tokens used to create the 5 minute cache entry.\n\n- `cache_creation_input_tokens: Integer`\n\nThe number of input tokens used to create the cache entry.\n\n- `cache_read_input_tokens: Integer`\n\nThe number of input tokens read from the cache.\n\n- `input_tokens: Integer`\n\nThe number of input tokens which were used.\n\n- `output_tokens: Integer`\n\nThe number of output tokens which were used.\n\n- `server_tool_use: ServerToolUsage`\n\nThe number of server tool requests.\n\n- `web_search_requests: Integer`\n\nThe number of web search tool requests.\n\n- `service_tier: :standard | :priority | :batch`\n\nIf the request used the priority, standard, or batch tier.\n\n- `class MessageBatchErroredResult`\n\n- `error: ErrorResponse`\n\n- `error: ErrorObject`\n\n- `class InvalidRequestError`\n\n- `type: :invalid_request_error`\n\n- `:invalid_request_error`\n\n- `class AuthenticationError`\n\n- `type: :authentication_error`\n\n- `:authentication_error`\n\n- `class BillingError`\n\n- `type: :billing_error`\n\n- `class PermissionError`\n\n- `type: :permission_error`\n\n- `:permission_error`\n\n- `class NotFoundError`\n\n- `type: :not_found_error`\n\n- `class RateLimitError`\n\n- `type: :rate_limit_error`\n\n- `:rate_limit_error`\n\n- `class GatewayTimeoutError`\n\n- `type: :timeout_error`\n\n- `class APIErrorObject`\n\n- `class OverloadedError`\n\n- `type: :overloaded_error`\n\n- `:overloaded_error`\n\n- `request_id: String`\n\n- `class MessageBatchCanceledResult`\n\n- `class MessageBatchExpiredResult`",
  "code_samples": [
    {
      "code": "[{\"type\": \"text\", \"text\": \"Hi, I'm Claude.\"}]",
      "language": "json"
    },
    {
      "code": "[\n            {\"role\": \"user\", \"content\": \"What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun\"},\n            {\"role\": \"assistant\", \"content\": \"The best answer is (\"}\n          ]",
      "language": "json"
    },
    {
      "code": "[{\"type\": \"text\", \"text\": \"B)\"}]",
      "language": "json"
    },
    {
      "code": "require \"anthropic\"\n\nanthropic = Anthropic::Client.new(api_key: \"my-anthropic-api-key\")\n\nmessage_batch_individual_response = anthropic.messages.batches.results(\"message_batch_id\")\n\nputs(message_batch_individual_response)",
      "language": "ruby"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Results",
      "id": "results"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Returns",
      "id": "returns"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    }
  ],
  "url": "llms-txt#retrieve-message-batch-results-(ruby)",
  "links": []
}