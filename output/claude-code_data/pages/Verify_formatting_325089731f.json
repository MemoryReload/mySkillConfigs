{
  "title": "Verify formatting",
  "content": "print(\"\\n--- Verification ---\")\nprint(f\"✓ Tool results sent in single user message: {len(tool_results)} results\")\nprint(\"✓ No text before tool results in content array\")\nprint(\"✓ Conversation formatted correctly for future parallel tool use\")\ntypescript TypeScript\n#!/usr/bin/env node\n// Test script to verify parallel tool calls with the Claude API\n\nimport { Anthropic } from '@anthropic-ai/sdk';\n\nconst anthropic = new Anthropic({\n  apiKey: process.env.ANTHROPIC_API_KEY\n});\n\n// Define tools\nconst tools = [\n  {\n    name: \"get_weather\",\n    description: \"Get the current weather in a given location\",\n    input_schema: {\n      type: \"object\",\n      properties: {\n        location: {\n          type: \"string\",\n          description: \"The city and state, e.g. San Francisco, CA\"\n        }\n      },\n      required: [\"location\"]\n    }\n  },\n  {\n    name: \"get_time\",\n    description: \"Get the current time in a given timezone\",\n    input_schema: {\n      type: \"object\",\n      properties: {\n        timezone: {\n          type: \"string\",\n          description: \"The timezone, e.g. America/New_York\"\n        }\n      },\n      required: [\"timezone\"]\n    }\n  }\n];\n\nasync function testParallelTools() {\n  // Make initial request\n  console.log(\"Requesting parallel tool calls...\");\n  const response = await anthropic.messages.create({\n    model: \"claude-sonnet-4-5\",\n    max_tokens: 1024,\n    messages: [{\n      role: \"user\",\n      content: \"What's the weather in SF and NYC, and what time is it there?\"\n    }],\n    tools: tools\n  });\n\n// Check for parallel tool calls\n  const toolUses = response.content.filter(block => block.type === \"tool_use\");\n  console.log(`\\n✓ Claude made ${toolUses.length} tool calls`);\n\nif (toolUses.length > 1) {\n    console.log(\"✓ Parallel tool calls detected!\");\n    toolUses.forEach(tool => {\n      console.log(`  - ${tool.name}: ${JSON.stringify(tool.input)}`);\n    });\n  } else {\n    console.log(\"✗ No parallel tool calls detected\");\n  }\n\n// Simulate tool execution and format results correctly\n  const toolResults = toolUses.map(toolUse => {\n    let result;\n    if (toolUse.name === \"get_weather\") {\n      result = toolUse.input.location.includes(\"San Francisco\")\n        ? \"San Francisco: 68°F, partly cloudy\"\n        : \"New York: 45°F, clear skies\";\n    } else {\n      result = toolUse.input.timezone.includes(\"Los_Angeles\")\n        ? \"2:30 PM PST\"\n        : \"5:30 PM EST\";\n    }\n\nreturn {\n      type: \"tool_result\",\n      tool_use_id: toolUse.id,\n      content: result\n    };\n  });\n\n// Get final response with correct formatting\n  console.log(\"\\nGetting final response...\");\n  const finalResponse = await anthropic.messages.create({\n    model: \"claude-sonnet-4-5\",\n    max_tokens: 1024,\n    messages: [\n      { role: \"user\", content: \"What's the weather in SF and NYC, and what time is it there?\" },\n      { role: \"assistant\", content: response.content },\n      { role: \"user\", content: toolResults }  // All results in one message!\n    ],\n    tools: tools\n  });\n\nconsole.log(`\\nClaude's response:\\n${finalResponse.content[0].text}`);\n\n// Verify formatting\n  console.log(\"\\n--- Verification ---\");\n  console.log(`✓ Tool results sent in single user message: ${toolResults.length} results`);\n  console.log(\"✓ No text before tool results in content array\");\n  console.log(\"✓ Conversation formatted correctly for future parallel tool use\");\n}\n\ntestParallelTools().catch(console.error);\ntext\nFor maximum efficiency, whenever you need to perform multiple independent operations, invoke all relevant tools simultaneously rather than sequentially.\ntext\n<use_parallel_tool_calls>\nFor maximum efficiency, whenever you perform multiple independent operations, invoke all relevant tools simultaneously rather than sequentially. Prioritize calling tools in parallel whenever possible. For example, when reading 3 files, run 3 tool calls in parallel to read all 3 files into context at the same time. When running multiple read-only commands like `ls` or `list_dir`, always run all of the commands in parallel. Err on the side of maximizing parallel tool calls rather than running too many tools sequentially.\n</use_parallel_tool_calls>\npython",
  "code_samples": [
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\nThis script demonstrates:\n- How to properly format parallel tool calls and results\n- How to verify that parallel calls are being made\n- The correct message structure that encourages future parallel tool use\n- Common mistakes to avoid (like text before tool results)\n\nRun this script to test your implementation and ensure Claude is making parallel tool calls effectively.\n\n</section>\n\n#### Maximizing parallel tool use\n\nWhile Claude 4 models have excellent parallel tool use capabilities by default, you can increase the likelihood of parallel tool execution across all models with targeted prompting:\n\n<section title=\"System prompts for parallel tool use\">\n\nFor Claude 4 models (Opus 4, and Sonnet 4), add this to your system prompt:",
      "language": "unknown"
    },
    {
      "code": "For even stronger parallel tool use (recommended if the default isn't sufficient), use:",
      "language": "unknown"
    },
    {
      "code": "</section>\n<section title=\"User message prompting\">\n\nYou can also encourage parallel tool use within specific user messages:",
      "language": "unknown"
    }
  ],
  "headings": [],
  "url": "llms-txt#verify-formatting",
  "links": []
}