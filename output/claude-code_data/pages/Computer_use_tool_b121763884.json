{
  "title": "Computer use tool",
  "content": "Claude can interact with computer environments through the computer use tool, which provides screenshot capabilities and mouse/keyboard control for autonomous desktop interaction.\n\n<Note>\nComputer use is currently in beta and requires a [beta header](/docs/en/api/beta-headers):\n- `\"computer-use-2025-11-24\"` for Claude Opus 4.5\n- `\"computer-use-2025-01-24\"` for Claude Sonnet 4.5, Haiku 4.5, Opus 4.1, Sonnet 4, Opus 4, and Sonnet 3.7 ([deprecated](/docs/en/about-claude/model-deprecations))\n\nPlease reach out through our [feedback form](https://forms.gle/H6UFuXaaLywri9hz6) to share your feedback on this feature.\n</Note>\n\nComputer use is a beta feature that enables Claude to interact with desktop environments. This tool provides:\n\n- **Screenshot capture**: See what's currently displayed on screen\n- **Mouse control**: Click, drag, and move the cursor\n- **Keyboard input**: Type text and use keyboard shortcuts\n- **Desktop automation**: Interact with any application or interface\n\nWhile computer use can be augmented with other tools like bash and text editor for more comprehensive automation workflows, computer use specifically refers to the computer use tool's capability to see and control desktop environments.\n\n## Model compatibility\n\nComputer use is available for the following Claude models:\n\n| Model | Tool Version | Beta Flag |\n|-------|--------------|-----------|\n| Claude Opus 4.5 | `computer_20251124` | `computer-use-2025-11-24` |\n| All other supported models | `computer_20250124` | `computer-use-2025-01-24` |\n\n<Note>\nClaude Opus 4.5 introduces the `computer_20251124` tool version with new capabilities including the zoom action for detailed screen region inspection. All other models (Sonnet 4.5, Haiku 4.5, Sonnet 4, Opus 4, Opus 4.1, and Sonnet 3.7) use the `computer_20250124` tool version.\n</Note>\n\n<Warning>\nOlder tool versions are not guaranteed to be backwards-compatible with newer models. Always use the tool version that corresponds to your model version.\n</Warning>\n\n## Security considerations\n\nComputer use is a beta feature with unique risks distinct from standard API features. These risks are heightened when interacting with the internet.\n\n<Warning>\nTo minimize risks, consider taking precautions such as:\n\n1. Using a dedicated virtual machine or container with minimal privileges to prevent direct system attacks or accidents.\n2. Avoiding giving the model access to sensitive data, such as account login information, to prevent information theft.\n3. Limiting internet access to an allowlist of domains to reduce exposure to malicious content.\n4. Asking a human to confirm decisions that may result in meaningful real-world consequences as well as any tasks requiring affirmative consent, such as accepting cookies, executing financial transactions, or agreeing to terms of service.\n</Warning>\n\nIn some circumstances, Claude will follow commands found in content even if it conflicts with the user's instructions. For example, Claude instructions on webpages or contained in images may override instructions or cause Claude to make mistakes. We suggest taking precautions to isolate Claude from sensitive data and actions to avoid risks related to prompt injection.\n\nWe've trained the model to resist these prompt injections and have added an extra layer of defense. If you use our computer use tools, we'll automatically run classifiers on your prompts to flag potential instances of prompt injections. When these classifiers identify potential prompt injections in screenshots, they will automatically steer the model to ask for user confirmation before proceeding with the next action. We recognize that this extra protection won't be ideal for every use case (for example, use cases without a human in the loop), so if you'd like to opt out and turn it off, please [contact us](https://support.claude.com/en/).\n\nWe still suggest taking precautions to isolate Claude from sensitive data and actions to avoid risks related to prompt injection.\n\nFinally, please inform end users of relevant risks and obtain their consent prior to enabling computer use in your own products.\n\n<Card\n  title=\"Computer use reference implementation\"\n  icon=\"computer\"\n  href=\"https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo\"\n>\n\nGet started quickly with our computer use reference implementation that includes a web interface, Docker container, example tool implementations, and an agent loop.\n\n**Note:** The implementation has been updated to include new tools for both Claude 4 models and Claude Sonnet 3.7. Be sure to pull the latest version of the repo to access these new features.\n\n<Tip>\n  Please use [this form](https://forms.gle/BT1hpBrqDPDUrCqo7) to provide\n  feedback on the quality of the model responses, the API itself, or the quality\n  of the documentation - we cannot wait to hear from you!\n</Tip>\n\nHere's how to get started with computer use:\n\n<Note>\nA beta header is only required for the computer use tool.\n\nThe example above shows all three tools being used together, which requires the beta header because it includes the computer use tool.\n</Note>\n\n## How computer use works\n\n<Steps>\n  <Step\n    title=\"Provide Claude with the computer use tool and a user prompt\"\n    icon=\"tool\"\n  >\n    - Add the computer use tool (and optionally other tools) to your API request.\n    - Include a user prompt that requires desktop interaction, e.g., \"Save a picture of a cat to my desktop.\"\n  </Step>\n  <Step title=\"Claude decides to use the computer use tool\" icon=\"wrench\">\n    - Claude assesses if the computer use tool can help with the user's query.\n    - If yes, Claude constructs a properly formatted tool use request.\n    - The API response has a `stop_reason` of `tool_use`, signaling Claude's intent.\n  </Step>\n  <Step\n    title=\"Extract tool input, evaluate the tool on a computer, and return results\"\n    icon=\"computer\"\n  >\n    - On your end, extract the tool name and input from Claude's request.\n    - Use the tool on a container or Virtual Machine.\n    - Continue the conversation with a new `user` message containing a `tool_result` content block.\n  </Step>\n  <Step\n    title=\"Claude continues calling computer use tools until it's completed the task\"\n    icon=\"arrows-clockwise\"\n  >\n    - Claude analyzes the tool results to determine if more tool use is needed or the task has been completed.\n    - If Claude decides it needs another tool, it responds with another `tool_use` `stop_reason` and you should return to step 3.\n    - Otherwise, it crafts a text response to the user.\n  </Step>\n</Steps>\n\nWe refer to the repetition of steps 3 and 4 without user input as the \"agent loop\" - i.e., Claude responding with a tool use request and your application responding to Claude with the results of evaluating that request.\n\n### The computing environment\n\nComputer use requires a sandboxed computing environment where Claude can safely interact with applications and the web. This environment includes:\n\n1. **Virtual display**: A virtual X11 display server (using Xvfb) that renders the desktop interface Claude will see through screenshots and control with mouse/keyboard actions.\n\n2. **Desktop environment**: A lightweight UI with window manager (Mutter) and panel (Tint2) running on Linux, which provides a consistent graphical interface for Claude to interact with.\n\n3. **Applications**: Pre-installed Linux applications like Firefox, LibreOffice, text editors, and file managers that Claude can use to complete tasks.\n\n4. **Tool implementations**: Integration code that translates Claude's abstract tool requests (like \"move mouse\" or \"take screenshot\") into actual operations in the virtual environment.\n\n5. **Agent loop**: A program that handles communication between Claude and the environment, sending Claude's actions to the environment and returning the results (screenshots, command outputs) back to Claude.\n\nWhen you use computer use, Claude doesn't directly connect to this environment. Instead, your application:\n\n1. Receives Claude's tool use requests\n2. Translates them into actions in your computing environment\n3. Captures the results (screenshots, command outputs, etc.)\n4. Returns these results to Claude\n\nFor security and isolation, the reference implementation runs all of this inside a Docker container with appropriate port mappings for viewing and interacting with the environment.\n\n## How to implement computer use\n\n### Start with our reference implementation\n\nWe have built a [reference implementation](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo) that includes everything you need to get started quickly with computer use:\n\n- A [containerized environment](https://github.com/anthropics/anthropic-quickstarts/blob/main/computer-use-demo/Dockerfile) suitable for computer use with Claude\n- Implementations of [the computer use tools](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo/computer_use_demo/tools)\n- An [agent loop](https://github.com/anthropics/anthropic-quickstarts/blob/main/computer-use-demo/computer_use_demo/loop.py) that interacts with the Claude API and executes the computer use tools\n- A web interface to interact with the container, agent loop, and tools.\n\n### Understanding the multi-agent loop\n\nThe core of computer use is the \"agent loop\" - a cycle where Claude requests tool actions, your application executes them, and returns results to Claude. Here's a simplified example:\n\nThe loop continues until either Claude responds without requesting any tools (task completion) or the maximum iteration limit is reached. This safeguard prevents potential infinite loops that could result in unexpected API costs.\n\nWe recommend trying the reference implementation out before reading the rest of this documentation.\n\n### Optimize model performance with prompting\n\nHere are some tips on how to get the best quality outputs:\n\n1. Specify simple, well-defined tasks and provide explicit instructions for each step.\n2. Claude sometimes assumes outcomes of its actions without explicitly checking their results. To prevent this you can prompt Claude with `After each step, take a screenshot and carefully evaluate if you have achieved the right outcome. Explicitly show your thinking: \"I have evaluated step X...\" If not correct, try again. Only when you confirm a step was executed correctly should you move on to the next one.`\n3. Some UI elements (like dropdowns and scrollbars) might be tricky for Claude to manipulate using mouse movements. If you experience this, try prompting the model to use keyboard shortcuts.\n4. For repeatable tasks or UI interactions, include example screenshots and tool calls of successful outcomes in your prompt.\n5. If you need the model to log in, provide it with the username and password in your prompt inside xml tags like `<robot_credentials>`. Using computer use within applications that require login increases the risk of bad outcomes as a result of prompt injection. Please review our [guide on mitigating prompt injections](/docs/en/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks) before providing the model with login credentials.\n\n<Tip>\n  If you repeatedly encounter a clear set of issues or know in advance the tasks\n  Claude will need to complete, use the system prompt to provide Claude with\n  explicit tips or instructions on how to do the tasks successfully.\n</Tip>\n\nWhen one of the Anthropic-defined tools is requested via the Claude API, a computer use-specific system prompt is generated. It's similar to the [tool use system prompt](/docs/en/agents-and-tools/tool-use/implement-tool-use#tool-use-system-prompt) but starts with:\n\n> You have access to a set of functions you can use to answer the user's question. This includes access to a sandboxed computing environment. You do NOT currently have the ability to inspect files or interact with external resources, except by invoking the below functions.\n\nAs with regular tool use, the user-provided `system_prompt` field is still respected and used in the construction of the combined system prompt.\n\n### Available actions\n\nThe computer use tool supports these actions:\n\n**Basic actions (all versions)**\n- **screenshot** - Capture the current display\n- **left_click** - Click at coordinates `[x, y]`\n- **type** - Type text string\n- **key** - Press key or key combination (e.g., \"ctrl+s\")\n- **mouse_move** - Move cursor to coordinates\n\n**Enhanced actions (`computer_20250124`)**\nAvailable in Claude 4 models and Claude Sonnet 3.7:\n- **scroll** - Scroll in any direction with amount control\n- **left_click_drag** - Click and drag between coordinates\n- **right_click**, **middle_click** - Additional mouse buttons\n- **double_click**, **triple_click** - Multiple clicks\n- **left_mouse_down**, **left_mouse_up** - Fine-grained click control\n- **hold_key** - Hold down a key for a specified duration (in seconds)\n- **wait** - Pause between actions\n\n**Enhanced actions (`computer_20251124`)**\nAvailable in Claude Opus 4.5:\n- All actions from `computer_20250124`\n- **zoom** - View a specific region of the screen at full resolution. Requires `enable_zoom: true` in tool definition. Takes a `region` parameter with coordinates `[x1, y1, x2, y2]` defining top-left and bottom-right corners of the area to inspect.\n\n<section title=\"Example actions\">\n\n<section title=\"Modifier keys with click and scroll actions\">\n\nTo hold modifier keys (like Shift, Ctrl, or Alt) while performing click or scroll actions, use the `text` parameter on those actions. This is different from `hold_key`, which simply holds a key for a duration without performing other actions.\n\nThe `text` parameter in click/scroll actions accepts modifier keys like `shift`, `ctrl`, `alt`, and `super` (for the Command/Windows key).\n\n| Parameter | Required | Description |\n|-----------|----------|-------------|\n| `type` | Yes | Tool version (`computer_20251124`, `computer_20250124`, or `computer_20241022`) |\n| `name` | Yes | Must be \"computer\" |\n| `display_width_px` | Yes | Display width in pixels |\n| `display_height_px` | Yes | Display height in pixels |\n| `display_number` | No | Display number for X11 environments |\n| `enable_zoom` | No | Enable zoom action (`computer_20251124` only). Set to `true` to allow Claude to zoom into specific screen regions. Default: `false` |\n\n<Note>\n**Important**: The computer use tool must be explicitly executed by your application - Claude cannot execute it directly. You are responsible for implementing the screenshot capture, mouse movements, keyboard inputs, and other actions based on Claude's requests.\n</Note>\n\n### Enable thinking capability in Claude 4 models and Claude Sonnet 3.7\n\nClaude Sonnet 3.7 introduced a new \"thinking\" capability that allows you to see the model's reasoning process as it works through complex tasks. This feature helps you understand how Claude is approaching a problem and can be particularly valuable for debugging or educational purposes.\n\nTo enable thinking, add a `thinking` parameter to your API request:\n\nThe `budget_tokens` parameter specifies how many tokens Claude can use for thinking. This is subtracted from your overall `max_tokens` budget.\n\nWhen thinking is enabled, Claude will return its reasoning process as part of the response, which can help you:\n\n1. Understand the model's decision-making process\n2. Identify potential issues or misconceptions\n3. Learn from Claude's approach to problem-solving\n4. Get more visibility into complex multi-step operations\n\nHere's an example of what thinking output might look like:\n\n### Augmenting computer use with other tools\n\nThe computer use tool can be combined with other tools to create more powerful automation workflows. This is particularly useful when you need to:\n- Execute system commands ([bash tool](/docs/en/agents-and-tools/tool-use/bash-tool))\n- Edit configuration files or scripts ([text editor tool](/docs/en/agents-and-tools/tool-use/text-editor-tool))\n- Integrate with custom APIs or services (custom tools)\n\n### Build a custom computer use environment\n\nThe [reference implementation](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo) is meant to help you get started with computer use. It includes all of the components needed have Claude use a computer. However, you can build your own environment for computer use to suit your needs. You'll need:\n\n- A virtualized or containerized environment suitable for computer use with Claude\n- An implementation of at least one of the Anthropic-defined computer use tools\n- An agent loop that interacts with the Claude API and executes the `tool_use` results using your tool implementations\n- An API or UI that allows user input to start the agent loop\n\n#### Implement the computer use tool\n\nThe computer use tool is implemented as a schema-less tool. When using this tool, you don't need to provide an input schema as with other tools; the schema is built into Claude's model and can't be modified.\n\n<Steps>\n  <Step title=\"Set up your computing environment\">\n    Create a virtual display or connect to an existing display that Claude will interact with. This typically involves setting up Xvfb (X Virtual Framebuffer) or similar technology.\n  </Step>\n  <Step title=\"Implement action handlers\">\n    Create functions to handle each action type that Claude might request:\n    \n  </Step>\n  <Step title=\"Process Claude's tool calls\">\n    Extract and execute tool calls from Claude's responses:\n    \n  </Step>\n  <Step title=\"Implement the agent loop\">\n    Create a loop that continues until Claude completes the task:\n    \n  </Step>\n</Steps>\n\nWhen implementing the computer use tool, various errors may occur. Here's how to handle them:\n\n<section title=\"Screenshot capture failure\">\n\nIf screenshot capture fails, return an appropriate error message:\n\n<section title=\"Invalid coordinates\">\n\nIf Claude provides coordinates outside the display bounds:\n\n<section title=\"Action execution failure\">\n\nIf an action fails to execute:\n\n#### Handle coordinate scaling for higher resolutions\n\nThe API constrains images to a maximum of 1568 pixels on the longest edge and approximately 1.15 megapixels total (see [image resizing](/docs/en/build-with-claude/vision#evaluate-image-size) for details). For example, a 1512x982 screen gets downsampled to approximately 1330x864. Claude analyzes this smaller image and returns coordinates in that space, but your tool executes clicks in the original screen space.\n\nThis can cause Claude's click coordinates to miss their targets unless you handle the coordinate transformation.\n\nTo fix this, resize screenshots yourself and scale Claude's coordinates back up:\n\n<CodeGroup>\n```python Python\nimport math\n\ndef get_scale_factor(width, height):\n    \"\"\"Calculate scale factor to meet API constraints.\"\"\"\n    long_edge = max(width, height)\n    total_pixels = width * height\n\nlong_edge_scale = 1568 / long_edge\n    total_pixels_scale = math.sqrt(1_150_000 / total_pixels)\n\nreturn min(1.0, long_edge_scale, total_pixels_scale)",
  "code_samples": [
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n<Note>\nA beta header is only required for the computer use tool.\n\nThe example above shows all three tools being used together, which requires the beta header because it includes the computer use tool.\n</Note>\n\n---\n\n## How computer use works\n\n<Steps>\n  <Step\n    title=\"Provide Claude with the computer use tool and a user prompt\"\n    icon=\"tool\"\n  >\n    - Add the computer use tool (and optionally other tools) to your API request.\n    - Include a user prompt that requires desktop interaction, e.g., \"Save a picture of a cat to my desktop.\"\n  </Step>\n  <Step title=\"Claude decides to use the computer use tool\" icon=\"wrench\">\n    - Claude assesses if the computer use tool can help with the user's query.\n    - If yes, Claude constructs a properly formatted tool use request.\n    - The API response has a `stop_reason` of `tool_use`, signaling Claude's intent.\n  </Step>\n  <Step\n    title=\"Extract tool input, evaluate the tool on a computer, and return results\"\n    icon=\"computer\"\n  >\n    - On your end, extract the tool name and input from Claude's request.\n    - Use the tool on a container or Virtual Machine.\n    - Continue the conversation with a new `user` message containing a `tool_result` content block.\n  </Step>\n  <Step\n    title=\"Claude continues calling computer use tools until it's completed the task\"\n    icon=\"arrows-clockwise\"\n  >\n    - Claude analyzes the tool results to determine if more tool use is needed or the task has been completed.\n    - If Claude decides it needs another tool, it responds with another `tool_use` `stop_reason` and you should return to step 3.\n    - Otherwise, it crafts a text response to the user.\n  </Step>\n</Steps>\n\nWe refer to the repetition of steps 3 and 4 without user input as the \"agent loop\" - i.e., Claude responding with a tool use request and your application responding to Claude with the results of evaluating that request.\n\n### The computing environment\n\nComputer use requires a sandboxed computing environment where Claude can safely interact with applications and the web. This environment includes:\n\n1. **Virtual display**: A virtual X11 display server (using Xvfb) that renders the desktop interface Claude will see through screenshots and control with mouse/keyboard actions.\n\n2. **Desktop environment**: A lightweight UI with window manager (Mutter) and panel (Tint2) running on Linux, which provides a consistent graphical interface for Claude to interact with.\n\n3. **Applications**: Pre-installed Linux applications like Firefox, LibreOffice, text editors, and file managers that Claude can use to complete tasks.\n\n4. **Tool implementations**: Integration code that translates Claude's abstract tool requests (like \"move mouse\" or \"take screenshot\") into actual operations in the virtual environment.\n\n5. **Agent loop**: A program that handles communication between Claude and the environment, sending Claude's actions to the environment and returning the results (screenshots, command outputs) back to Claude.\n\nWhen you use computer use, Claude doesn't directly connect to this environment. Instead, your application:\n\n1. Receives Claude's tool use requests\n2. Translates them into actions in your computing environment\n3. Captures the results (screenshots, command outputs, etc.)\n4. Returns these results to Claude\n\nFor security and isolation, the reference implementation runs all of this inside a Docker container with appropriate port mappings for viewing and interacting with the environment.\n\n---\n\n## How to implement computer use\n\n### Start with our reference implementation\n\nWe have built a [reference implementation](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo) that includes everything you need to get started quickly with computer use:\n\n- A [containerized environment](https://github.com/anthropics/anthropic-quickstarts/blob/main/computer-use-demo/Dockerfile) suitable for computer use with Claude\n- Implementations of [the computer use tools](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo/computer_use_demo/tools)\n- An [agent loop](https://github.com/anthropics/anthropic-quickstarts/blob/main/computer-use-demo/computer_use_demo/loop.py) that interacts with the Claude API and executes the computer use tools\n- A web interface to interact with the container, agent loop, and tools.\n\n### Understanding the multi-agent loop\n\nThe core of computer use is the \"agent loop\" - a cycle where Claude requests tool actions, your application executes them, and returns results to Claude. Here's a simplified example:",
      "language": "unknown"
    },
    {
      "code": "The loop continues until either Claude responds without requesting any tools (task completion) or the maximum iteration limit is reached. This safeguard prevents potential infinite loops that could result in unexpected API costs.\n\nWe recommend trying the reference implementation out before reading the rest of this documentation.\n\n### Optimize model performance with prompting\n\nHere are some tips on how to get the best quality outputs:\n\n1. Specify simple, well-defined tasks and provide explicit instructions for each step.\n2. Claude sometimes assumes outcomes of its actions without explicitly checking their results. To prevent this you can prompt Claude with `After each step, take a screenshot and carefully evaluate if you have achieved the right outcome. Explicitly show your thinking: \"I have evaluated step X...\" If not correct, try again. Only when you confirm a step was executed correctly should you move on to the next one.`\n3. Some UI elements (like dropdowns and scrollbars) might be tricky for Claude to manipulate using mouse movements. If you experience this, try prompting the model to use keyboard shortcuts.\n4. For repeatable tasks or UI interactions, include example screenshots and tool calls of successful outcomes in your prompt.\n5. If you need the model to log in, provide it with the username and password in your prompt inside xml tags like `<robot_credentials>`. Using computer use within applications that require login increases the risk of bad outcomes as a result of prompt injection. Please review our [guide on mitigating prompt injections](/docs/en/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks) before providing the model with login credentials.\n\n<Tip>\n  If you repeatedly encounter a clear set of issues or know in advance the tasks\n  Claude will need to complete, use the system prompt to provide Claude with\n  explicit tips or instructions on how to do the tasks successfully.\n</Tip>\n\n### System prompts\n\nWhen one of the Anthropic-defined tools is requested via the Claude API, a computer use-specific system prompt is generated. It's similar to the [tool use system prompt](/docs/en/agents-and-tools/tool-use/implement-tool-use#tool-use-system-prompt) but starts with:\n\n> You have access to a set of functions you can use to answer the user's question. This includes access to a sandboxed computing environment. You do NOT currently have the ability to inspect files or interact with external resources, except by invoking the below functions.\n\nAs with regular tool use, the user-provided `system_prompt` field is still respected and used in the construction of the combined system prompt.\n\n### Available actions\n\nThe computer use tool supports these actions:\n\n**Basic actions (all versions)**\n- **screenshot** - Capture the current display\n- **left_click** - Click at coordinates `[x, y]`\n- **type** - Type text string\n- **key** - Press key or key combination (e.g., \"ctrl+s\")\n- **mouse_move** - Move cursor to coordinates\n\n**Enhanced actions (`computer_20250124`)**\nAvailable in Claude 4 models and Claude Sonnet 3.7:\n- **scroll** - Scroll in any direction with amount control\n- **left_click_drag** - Click and drag between coordinates\n- **right_click**, **middle_click** - Additional mouse buttons\n- **double_click**, **triple_click** - Multiple clicks\n- **left_mouse_down**, **left_mouse_up** - Fine-grained click control\n- **hold_key** - Hold down a key for a specified duration (in seconds)\n- **wait** - Pause between actions\n\n**Enhanced actions (`computer_20251124`)**\nAvailable in Claude Opus 4.5:\n- All actions from `computer_20250124`\n- **zoom** - View a specific region of the screen at full resolution. Requires `enable_zoom: true` in tool definition. Takes a `region` parameter with coordinates `[x1, y1, x2, y2]` defining top-left and bottom-right corners of the area to inspect.\n\n<section title=\"Example actions\">",
      "language": "unknown"
    },
    {
      "code": "</section>\n\n<section title=\"Modifier keys with click and scroll actions\">\n\nTo hold modifier keys (like Shift, Ctrl, or Alt) while performing click or scroll actions, use the `text` parameter on those actions. This is different from `hold_key`, which simply holds a key for a duration without performing other actions.",
      "language": "unknown"
    },
    {
      "code": "The `text` parameter in click/scroll actions accepts modifier keys like `shift`, `ctrl`, `alt`, and `super` (for the Command/Windows key).\n\n</section>\n\n### Tool parameters\n\n| Parameter | Required | Description |\n|-----------|----------|-------------|\n| `type` | Yes | Tool version (`computer_20251124`, `computer_20250124`, or `computer_20241022`) |\n| `name` | Yes | Must be \"computer\" |\n| `display_width_px` | Yes | Display width in pixels |\n| `display_height_px` | Yes | Display height in pixels |\n| `display_number` | No | Display number for X11 environments |\n| `enable_zoom` | No | Enable zoom action (`computer_20251124` only). Set to `true` to allow Claude to zoom into specific screen regions. Default: `false` |\n\n<Note>\n**Important**: The computer use tool must be explicitly executed by your application - Claude cannot execute it directly. You are responsible for implementing the screenshot capture, mouse movements, keyboard inputs, and other actions based on Claude's requests.\n</Note>\n\n### Enable thinking capability in Claude 4 models and Claude Sonnet 3.7\n\nClaude Sonnet 3.7 introduced a new \"thinking\" capability that allows you to see the model's reasoning process as it works through complex tasks. This feature helps you understand how Claude is approaching a problem and can be particularly valuable for debugging or educational purposes.\n\nTo enable thinking, add a `thinking` parameter to your API request:",
      "language": "unknown"
    },
    {
      "code": "The `budget_tokens` parameter specifies how many tokens Claude can use for thinking. This is subtracted from your overall `max_tokens` budget.\n\nWhen thinking is enabled, Claude will return its reasoning process as part of the response, which can help you:\n\n1. Understand the model's decision-making process\n2. Identify potential issues or misconceptions\n3. Learn from Claude's approach to problem-solving\n4. Get more visibility into complex multi-step operations\n\nHere's an example of what thinking output might look like:",
      "language": "unknown"
    },
    {
      "code": "### Augmenting computer use with other tools\n\nThe computer use tool can be combined with other tools to create more powerful automation workflows. This is particularly useful when you need to:\n- Execute system commands ([bash tool](/docs/en/agents-and-tools/tool-use/bash-tool))\n- Edit configuration files or scripts ([text editor tool](/docs/en/agents-and-tools/tool-use/text-editor-tool))\n- Integrate with custom APIs or services (custom tools)\n\n<CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n### Build a custom computer use environment\n\nThe [reference implementation](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo) is meant to help you get started with computer use. It includes all of the components needed have Claude use a computer. However, you can build your own environment for computer use to suit your needs. You'll need:\n\n- A virtualized or containerized environment suitable for computer use with Claude\n- An implementation of at least one of the Anthropic-defined computer use tools\n- An agent loop that interacts with the Claude API and executes the `tool_use` results using your tool implementations\n- An API or UI that allows user input to start the agent loop\n\n#### Implement the computer use tool\n\nThe computer use tool is implemented as a schema-less tool. When using this tool, you don't need to provide an input schema as with other tools; the schema is built into Claude's model and can't be modified.\n\n<Steps>\n  <Step title=\"Set up your computing environment\">\n    Create a virtual display or connect to an existing display that Claude will interact with. This typically involves setting up Xvfb (X Virtual Framebuffer) or similar technology.\n  </Step>\n  <Step title=\"Implement action handlers\">\n    Create functions to handle each action type that Claude might request:",
      "language": "unknown"
    },
    {
      "code": "</Step>\n  <Step title=\"Process Claude's tool calls\">\n    Extract and execute tool calls from Claude's responses:",
      "language": "unknown"
    },
    {
      "code": "</Step>\n  <Step title=\"Implement the agent loop\">\n    Create a loop that continues until Claude completes the task:",
      "language": "unknown"
    },
    {
      "code": "</Step>\n</Steps>\n\n#### Handle errors\n\nWhen implementing the computer use tool, various errors may occur. Here's how to handle them:\n\n<section title=\"Screenshot capture failure\">\n\nIf screenshot capture fails, return an appropriate error message:",
      "language": "unknown"
    },
    {
      "code": "</section>\n\n<section title=\"Invalid coordinates\">\n\nIf Claude provides coordinates outside the display bounds:",
      "language": "unknown"
    },
    {
      "code": "</section>\n\n<section title=\"Action execution failure\">\n\nIf an action fails to execute:",
      "language": "unknown"
    },
    {
      "code": "</section>\n\n#### Handle coordinate scaling for higher resolutions\n\nThe API constrains images to a maximum of 1568 pixels on the longest edge and approximately 1.15 megapixels total (see [image resizing](/docs/en/build-with-claude/vision#evaluate-image-size) for details). For example, a 1512x982 screen gets downsampled to approximately 1330x864. Claude analyzes this smaller image and returns coordinates in that space, but your tool executes clicks in the original screen space.\n\nThis can cause Claude's click coordinates to miss their targets unless you handle the coordinate transformation.\n\nTo fix this, resize screenshots yourself and scale Claude's coordinates back up:\n\n<CodeGroup>",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Overview",
      "id": "overview"
    },
    {
      "level": "h2",
      "text": "Model compatibility",
      "id": "model-compatibility"
    },
    {
      "level": "h2",
      "text": "Security considerations",
      "id": "security-considerations"
    },
    {
      "level": "h2",
      "text": "Quick start",
      "id": "quick-start"
    },
    {
      "level": "h2",
      "text": "How computer use works",
      "id": "how-computer-use-works"
    },
    {
      "level": "h3",
      "text": "The computing environment",
      "id": "the-computing-environment"
    },
    {
      "level": "h2",
      "text": "How to implement computer use",
      "id": "how-to-implement-computer-use"
    },
    {
      "level": "h3",
      "text": "Start with our reference implementation",
      "id": "start-with-our-reference-implementation"
    },
    {
      "level": "h3",
      "text": "Understanding the multi-agent loop",
      "id": "understanding-the-multi-agent-loop"
    },
    {
      "level": "h3",
      "text": "Optimize model performance with prompting",
      "id": "optimize-model-performance-with-prompting"
    },
    {
      "level": "h3",
      "text": "System prompts",
      "id": "system-prompts"
    },
    {
      "level": "h3",
      "text": "Available actions",
      "id": "available-actions"
    },
    {
      "level": "h3",
      "text": "Tool parameters",
      "id": "tool-parameters"
    },
    {
      "level": "h3",
      "text": "Enable thinking capability in Claude 4 models and Claude Sonnet 3.7",
      "id": "enable-thinking-capability-in-claude-4-models-and-claude-sonnet-3.7"
    },
    {
      "level": "h3",
      "text": "Augmenting computer use with other tools",
      "id": "augmenting-computer-use-with-other-tools"
    },
    {
      "level": "h3",
      "text": "Build a custom computer use environment",
      "id": "build-a-custom-computer-use-environment"
    }
  ],
  "url": "llms-txt#computer-use-tool",
  "links": []
}