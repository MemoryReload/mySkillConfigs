{
  "title": "Set the default model",
  "content": "DEFAULT_MODEL=\"claude-haiku-4-5-20251001\"\n\ndef classify_support_request(request, actual_intent):\n    # Define the prompt for the classification task\n    classification_prompt = f\"\"\"You will be acting as a customer support ticket classification system. \n        ...\n        ...The reasoning should be enclosed in <reasoning> tags and the intent in <intent> tags. Return only the reasoning and the intent.\n        \"\"\"\n\nmessage = client.messages.create(\n        model=DEFAULT_MODEL,\n        max_tokens=500,\n        temperature=0,\n        messages=[{\"role\": \"user\", \"content\": classification_prompt}],\n    )\n    usage = message.usage  # Get the usage statistics for the API call for how many input and output tokens were used.\n    reasoning_and_intent = message.content[0].text\n\n# Use Python's regular expressions library to extract `reasoning`.\n    reasoning_match = re.search(\n        r\"<reasoning>(.*?)</reasoning>\", reasoning_and_intent, re.DOTALL\n    )\n    reasoning = reasoning_match.group(1).strip() if reasoning_match else \"\"\n\n# Similarly, also extract the `intent`.\n    intent_match = re.search(r\"<intent>(.*?)</intent>\", reasoning_and_intent, re.DOTALL)\n    intent = intent_match.group(1).strip() if intent_match else \"\"\n\n# Check if the model's prediction is correct.\n    correct = actual_intent.strip() == intent.strip()\n\n# Return the reasoning, intent, correct, and usage.\n    return reasoning, intent, correct, usage\n```\n\nLet’s break down the edits we’ve made:\n* We added the `actual_intent` from our test cases into the `classify_support_request` method and set up a comparison to assess whether Claude’s intent classification matches our golden intent classification.\n* We extracted usage statistics for the API call to calculate cost based on input and output tokens used\n\n### Run your evaluation\n\nA proper evaluation requires clear thresholds and benchmarks to determine what is a good result. The script above will give us the runtime values for accuracy, response time, and cost per classification, but we still would need clearly established thresholds. For example:\n* **Accuracy:** 95% (out of 100 tests)\n* **Cost per classification:** 50% reduction on average (across 100 tests) from current routing method\n\nHaving these thresholds allows you to quickly and easily tell at scale, and with impartial empiricism, what method is best for you and what changes might need to be made to better fit your requirements.\n\n## Improve performance\n\nIn complex scenarios, it may be helpful to consider additional strategies to improve performance beyond standard [prompt engineering techniques](/docs/en/build-with-claude/prompt-engineering/overview) & [guardrail implementation strategies](/docs/en/test-and-evaluate/strengthen-guardrails/reduce-hallucinations). Here are some common scenarios:\n\n### Use a taxonomic hierarchy for cases with 20+ intent categories\n\nAs the number of classes grows, the number of examples required also expands, potentially making the prompt unwieldy. As an alternative, you can consider implementing a hierarchical classification system using a mixture of classifiers.\n1. Organize your intents in a taxonomic tree structure.\n2. Create a series of classifiers at every level of the tree, enabling a cascading routing approach.\n\nFor example, you might have a top-level classifier that broadly categorizes tickets into \"Technical Issues,\" \"Billing Questions,\" and \"General Inquiries.\" Each of these categories can then have its own sub-classifier to further refine the classification.\n\n![](/docs/images/ticket-hierarchy.png)\n\n* **Pros - greater nuance and accuracy:** You can create different prompts for each parent path, allowing for more targeted and context-specific classification. This can lead to improved accuracy and more nuanced handling of customer requests.\n\n* **Cons - increased latency:** Be advised that multiple classifiers can lead to increased latency, and we recommend implementing this approach with our fastest model, Haiku.\n\n### Use vector databases and similarity search retrieval to handle highly variable tickets\n\nDespite providing examples being the most effective way to improve performance, if support requests are highly variable, it can be hard to include enough examples in a single prompt.\n\nIn this scenario, you could employ a vector database to do similarity searches from a dataset of examples and retrieve the most relevant examples for a given query.\n\nThis approach, outlined in detail in our [classification recipe](https://platform.claude.com/cookbook/capabilities-classification-guide), has been shown to improve performance from 71% accuracy to 93% accuracy.\n\n### Account specifically for expected edge cases\n\nHere are some scenarios where Claude may misclassify tickets (there may be others that are unique to your situation). In these scenarios,consider providing explicit instructions or examples in the prompt of how Claude should handle the edge case:\n\n<section title=\"Customers make implicit requests\">\n\nCustomers often express needs indirectly. For example, \"I've been waiting for my package for over two weeks now\" may be an indirect request for order status.\n        * **Solution:** Provide Claude with some real customer examples of these kinds of requests, along with what the underlying intent is. You can get even better results if you include a classification rationale for particularly nuanced ticket intents, so that Claude can better generalize the logic to other tickets.\n    \n</section>\n    <section title=\"Claude prioritizes emotion over intent\">\n\nWhen customers express dissatisfaction, Claude may prioritize addressing the emotion over solving the underlying problem.\n        * **Solution:** Provide Claude with directions on when to prioritize customer sentiment or not. It can be something as simple as “Ignore all customer emotions. Focus only on analyzing the intent of the customer’s request and what information the customer might be asking for.”\n    \n</section>\n    <section title=\"Multiple issues cause issue prioritization confusion\">\n\nWhen customers present multiple issues in a single interaction, Claude may have difficulty identifying the primary concern.\n        * **Solution:** Clarify the prioritization of intents so thatClaude can better rank the extracted intents and identify the primary concern. \n    \n</section>\n\n## Integrate Claude into your greater support workflow\n\nProper integration requires that you make some decisions regarding how your Claude-based ticket routing script fits into the architecture of your greater ticket routing system.There are two ways you could do this:\n* **Push-based:** The support ticket system you’re using (e.g. Zendesk) triggers your code by sending a webhook event to your routing service, which then classifies the intent and routes it.\n    * This approach is more web-scalable, but needs you to expose a public endpoint.\n* **Pull-Based:** Your code pulls for the latest tickets based on a given schedule and routes them at pull time.\n    * This approach is easier to implement but might make unnecessary calls to the support ticket system when the pull frequency is too high or might be overly slow when the pull frequency is too low.\n\nFor either of these approaches, you will need to wrap your script in a service. The choice of approach depends on what APIs your support ticketing system provides.\n\n<CardGroup cols={2}>\n    <Card title=\"Classification cookbook\" icon=\"link\" href=\"https://platform.claude.com/cookbook/capabilities-classification-guide\">\n        Visit our classification cookbook for more example code and detailed eval guidance.\n    </Card>\n    <Card title=\"Claude Console\" icon=\"link\" href=\"/dashboard\">\n        Begin building and evaluating your workflow on the Claude Console.\n    </Card>\n</CardGroup>\n\n### Resources > Prompt Library",
  "code_samples": [],
  "headings": [
    {
      "level": "h3",
      "text": "Run your evaluation",
      "id": "run-your-evaluation-"
    },
    {
      "level": "h2",
      "text": "Improve performance",
      "id": "improve-performance"
    },
    {
      "level": "h3",
      "text": "Use a taxonomic hierarchy for cases with 20+ intent categories",
      "id": "use-a-taxonomic-hierarchy-for-cases-with-20+-intent-categories"
    },
    {
      "level": "h3",
      "text": "Use vector databases and similarity search retrieval to handle highly variable tickets",
      "id": "use-vector-databases-and-similarity-search-retrieval-to-handle-highly-variable-tickets"
    },
    {
      "level": "h3",
      "text": "Account specifically for expected edge cases",
      "id": "account-specifically-for-expected-edge-cases"
    },
    {
      "level": "h2",
      "text": "Integrate Claude into your greater support workflow",
      "id": "integrate-claude-into-your-greater-support-workflow"
    },
    {
      "level": "h3",
      "text": "Resources > Prompt Library",
      "id": "resources->-prompt-library"
    }
  ],
  "url": "llms-txt#set-the-default-model",
  "links": []
}