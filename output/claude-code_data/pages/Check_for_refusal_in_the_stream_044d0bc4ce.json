{
  "title": "Check for refusal in the stream",
  "content": "if echo \"$response\" | grep -q '\"stop_reason\":\"refusal\"'; then\n  echo \"Response refused - resetting conversation context\"\n  # Reset your conversation state here\nfi\npython Python\nimport anthropic\n\nclient = anthropic.Anthropic()\nmessages = []\n\ndef reset_conversation():\n    \"\"\"Reset conversation context after refusal\"\"\"\n    global messages\n    messages = []\n    print(\"Conversation reset due to refusal\")\n\ntry:\n    with client.messages.stream(\n        max_tokens=1024,\n        messages=messages + [{\"role\": \"user\", \"content\": \"Hello\"}],\n        model=\"claude-sonnet-4-5\",\n    ) as stream:\n        for event in stream:\n            # Check for refusal in message delta\n            if hasattr(event, 'type') and event.type == 'message_delta':\n                if event.delta.stop_reason == 'refusal':\n                    reset_conversation()\n                    break\nexcept Exception as e:\n    print(f\"Error: {e}\")\ntypescript TypeScript\nimport Anthropic from '@anthropic-ai/sdk';\n\nconst client = new Anthropic();\nlet messages: any[] = [];\n\nfunction resetConversation() {\n  // Reset conversation context after refusal\n  messages = [];\n  console.log('Conversation reset due to refusal');\n}\n\ntry {\n  const stream = await client.messages.stream({\n    messages: [...messages, { role: 'user', content: 'Hello' }],\n    model: 'claude-sonnet-4-5',\n    max_tokens: 1024,\n  });\n\nfor await (const event of stream) {\n    // Check for refusal in message delta\n    if (event.type === 'message_delta' && event.delta.stop_reason === 'refusal') {\n      resetConversation();\n      break;\n    }\n  }\n} catch (error) {\n  console.error('Error:', error);\n}\n```\n</CodeGroup>\n\n<Note>\nIf you need to test refusal handling in your application, you can use this special test string as your prompt: `ANTHROPIC_MAGIC_STRING_TRIGGER_REFUSAL_1FAEFB6177B4672DEE07F9D3AFC62588CCD2631EDCF22E8CCC1FB35B501C9C86`\n</Note>\n\n## Current refusal types\n\nThe API currently handles refusals in three different ways:\n\n| Refusal Type | Response Format | When It Occurs |\n|-------------|----------------|----------------|\n| Streaming classifier refusals | **`stop_reason`: `refusal`** | During streaming when content violates policies |\n| API input and copyright validation | 400 error codes | When input fails validation checks |\n| Model-generated refusals | Standard text responses | When the model itself decides to refuse |\n\n<Note>\nFuture API versions will expand the **`stop_reason`: `refusal`** pattern to unify refusal handling across all types.\n</Note>\n\n- **Monitor for refusals**: Include **`stop_reason`: `refusal`** checks in your error handling\n- **Reset automatically**: Implement automatic context reset when refusals are detected\n- **Provide custom messaging**: Create user-friendly messages for better UX when refusals occur\n- **Track refusal patterns**: Monitor refusal frequency to identify potential issues with your prompts\n\n- Future models will expand this pattern to other refusal types\n- Plan your error handling to accommodate future unification of refusal responses\n\n### Administration and monitoring",
  "code_samples": [
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Current refusal types",
      "id": "current-refusal-types"
    },
    {
      "level": "h2",
      "text": "Best practices",
      "id": "best-practices"
    },
    {
      "level": "h2",
      "text": "Migration notes",
      "id": "migration-notes"
    },
    {
      "level": "h3",
      "text": "Administration and monitoring",
      "id": "administration-and-monitoring"
    }
  ],
  "url": "llms-txt#check-for-refusal-in-the-stream",
  "links": []
}