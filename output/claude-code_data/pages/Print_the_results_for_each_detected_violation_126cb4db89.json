{
  "title": "Print the results for each detected violation",
  "content": "for violation in response_obj['violations']:\n    print(f\"\"\"Comment: {user_comments[violation['id']]}\nViolated Categories: {', '.join(violation['categories'])}\nExplanation: {violation['explanation']}\n\"\"\")\n```\nIn this example, the `batch_moderate_messages` function handles the moderation of an entire batch of messages with a single Claude API call.\nInside the function, a prompt is created that includes the list of messages to evaluate, the defined unsafe content categories, and their descriptions. The prompt directs Claude to return a JSON object listing all messages that contain violations. Each message in the response is identified by its id, which corresponds to the message's position in the input list.\nKeep in mind that finding the optimal batch size for your specific needs may require some experimentation. While larger batch sizes can lower costs, they might also lead to a slight decrease in quality. Additionally, you may need to increase the `max_tokens` parameter in the Claude API call to accommodate longer responses. For details on the maximum number of tokens your chosen model can output, refer to the [model comparison page](/docs/en/about-claude/models#model-comparison-table).\n\n<CardGroup cols={2}>\n  <Card title=\"Content moderation cookbook\" icon=\"link\" href=\"https://platform.claude.com/cookbook/misc-building-moderation-filter\">\n    View a fully implemented code-based example of how to use Claude for content moderation.\n  </Card>\n  <Card title=\"Guardrails guide\" icon=\"link\" href=\"/docs/en/test-and-evaluate/strengthen-guardrails/reduce-hallucinations\">\n    Explore our guardrails guide for techniques to moderate interactions with Claude.\n  </Card>\n</CardGroup>",
  "code_samples": [],
  "headings": [],
  "url": "llms-txt#print-the-results-for-each-detected-violation",
  "links": []
}