{
  "title": "Create a Text Completion (Ruby)",
  "content": "URL: https://platform.claude.com/docs/en/api/ruby/completions/create\n\n`completions.create(**kwargs) -> Completion`\n\n**post** `/v1/complete`\n\n[Legacy] Create a Text Completion.\n\nThe Text Completions API is a legacy API. We recommend using the [Messages API](https://docs.claude.com/en/api/messages) going forward.\n\nFuture models and features will not be compatible with Text Completions. See our [migration guide](https://docs.claude.com/en/api/migrating-from-text-completions-to-messages) for guidance in migrating from Text Completions to Messages.\n\n- `max_tokens_to_sample: Integer`\n\nThe maximum number of tokens to generate before stopping.\n\nNote that our models may stop _before_ reaching this maximum. This parameter only specifies the absolute maximum number of tokens to generate.\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `:\"claude-opus-4-5-20251101\" | :\"claude-opus-4-5\" | :\"claude-3-7-sonnet-latest\" | 17 more`\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `:\"claude-opus-4-5-20251101\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `:\"claude-opus-4-5\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `:\"claude-3-7-sonnet-latest\"`\n\nHigh-performance model with early extended thinking\n\n- `:\"claude-3-7-sonnet-20250219\"`\n\nHigh-performance model with early extended thinking\n\n- `:\"claude-3-5-haiku-latest\"`\n\nFastest and most compact model for near-instant responsiveness\n\n- `:\"claude-3-5-haiku-20241022\"`\n\n- `:\"claude-haiku-4-5\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `:\"claude-haiku-4-5-20251001\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `:\"claude-sonnet-4-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `:\"claude-sonnet-4-0\"`\n\nHigh-performance model with extended thinking\n\n- `:\"claude-4-sonnet-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `:\"claude-sonnet-4-5\"`\n\nOur best model for real-world agents and coding\n\n- `:\"claude-sonnet-4-5-20250929\"`\n\nOur best model for real-world agents and coding\n\n- `:\"claude-opus-4-0\"`\n\nOur most capable model\n\n- `:\"claude-opus-4-20250514\"`\n\nOur most capable model\n\n- `:\"claude-4-opus-20250514\"`\n\nOur most capable model\n\n- `:\"claude-opus-4-1-20250805\"`\n\nOur most capable model\n\n- `:\"claude-3-opus-latest\"`\n\nExcels at writing and complex tasks\n\n- `:\"claude-3-opus-20240229\"`\n\nExcels at writing and complex tasks\n\n- `:\"claude-3-haiku-20240307\"`\n\nOur previous most fast and cost-effective\n\nThe prompt that you want Claude to complete.\n\nFor proper response generation you will need to format your prompt using alternating `\n\nAssistant:` conversational turns. For example:\n\nSee [prompt validation](https://docs.claude.com/en/api/prompt-validation) and our guide to [prompt design](https://docs.claude.com/en/docs/intro-to-prompting) for more details.\n\n- `metadata: Metadata`\n\nAn object describing metadata about the request.\n\nAn external identifier for the user who is associated with the request.\n\nThis should be a uuid, hash value, or other opaque identifier. Anthropic may use this id to help detect abuse. Do not include any identifying information such as name, email address, or phone number.\n\n- `stop_sequences: Array[String]`\n\nSequences that will cause the model to stop generating.\n\nOur models stop on `\"\n\nHuman:\"`, and may include additional built-in stop sequences in the future. By providing the stop_sequences parameter, you may include additional strings that will cause the model to stop generating.\n\nWhether to incrementally stream the response using server-sent events.\n\nSee [streaming](https://docs.claude.com/en/api/streaming) for details.\n\n- `temperature: Float`\n\nAmount of randomness injected into the response.\n\nDefaults to `1.0`. Ranges from `0.0` to `1.0`. Use `temperature` closer to `0.0` for analytical / multiple choice, and closer to `1.0` for creative and generative tasks.\n\nNote that even with `temperature` of `0.0`, the results will not be fully deterministic.\n\nOnly sample from the top K options for each subsequent token.\n\nUsed to remove \"long tail\" low probability responses. [Learn more technical details here](https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277).\n\nRecommended for advanced use cases only. You usually only need to use `temperature`.\n\nUse nucleus sampling.\n\nIn nucleus sampling, we compute the cumulative distribution over all the options for each subsequent token in decreasing probability order and cut it off once it reaches a particular probability specified by `top_p`. You should either alter `temperature` or `top_p`, but not both.\n\nRecommended for advanced use cases only. You usually only need to use `temperature`.\n\n- `anthropic_beta: Array[AnthropicBeta]`\n\nOptional header to specify the beta version(s) you want to use.\n\n- `:\"message-batches-2024-09-24\" | :\"prompt-caching-2024-07-31\" | :\"computer-use-2024-10-22\" | 16 more`\n\n- `:\"message-batches-2024-09-24\"`\n\n- `:\"prompt-caching-2024-07-31\"`\n\n- `:\"computer-use-2024-10-22\"`\n\n- `:\"computer-use-2025-01-24\"`\n\n- `:\"pdfs-2024-09-25\"`\n\n- `:\"token-counting-2024-11-01\"`\n\n- `:\"token-efficient-tools-2025-02-19\"`\n\n- `:\"output-128k-2025-02-19\"`\n\n- `:\"files-api-2025-04-14\"`\n\n- `:\"mcp-client-2025-04-04\"`\n\n- `:\"mcp-client-2025-11-20\"`\n\n- `:\"dev-full-thinking-2025-05-14\"`\n\n- `:\"interleaved-thinking-2025-05-14\"`\n\n- `:\"code-execution-2025-05-22\"`\n\n- `:\"extended-cache-ttl-2025-04-11\"`\n\n- `:\"context-1m-2025-08-07\"`\n\n- `:\"context-management-2025-06-27\"`\n\n- `:\"model-context-window-exceeded-2025-08-26\"`\n\n- `:\"skills-2025-10-02\"`\n\nUnique object identifier.\n\nThe format and length of IDs may change over time.\n\n- `completion: String`\n\nThe resulting completion up to and excluding the stop sequences.\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `:\"claude-opus-4-5-20251101\" | :\"claude-opus-4-5\" | :\"claude-3-7-sonnet-latest\" | 17 more`\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `:\"claude-opus-4-5-20251101\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `:\"claude-opus-4-5\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `:\"claude-3-7-sonnet-latest\"`\n\nHigh-performance model with early extended thinking\n\n- `:\"claude-3-7-sonnet-20250219\"`\n\nHigh-performance model with early extended thinking\n\n- `:\"claude-3-5-haiku-latest\"`\n\nFastest and most compact model for near-instant responsiveness\n\n- `:\"claude-3-5-haiku-20241022\"`\n\n- `:\"claude-haiku-4-5\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `:\"claude-haiku-4-5-20251001\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `:\"claude-sonnet-4-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `:\"claude-sonnet-4-0\"`\n\nHigh-performance model with extended thinking\n\n- `:\"claude-4-sonnet-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `:\"claude-sonnet-4-5\"`\n\nOur best model for real-world agents and coding\n\n- `:\"claude-sonnet-4-5-20250929\"`\n\nOur best model for real-world agents and coding\n\n- `:\"claude-opus-4-0\"`\n\nOur most capable model\n\n- `:\"claude-opus-4-20250514\"`\n\nOur most capable model\n\n- `:\"claude-4-opus-20250514\"`\n\nOur most capable model\n\n- `:\"claude-opus-4-1-20250805\"`\n\nOur most capable model\n\n- `:\"claude-3-opus-latest\"`\n\nExcels at writing and complex tasks\n\n- `:\"claude-3-opus-20240229\"`\n\nExcels at writing and complex tasks\n\n- `:\"claude-3-haiku-20240307\"`\n\nOur previous most fast and cost-effective\n\n- `stop_reason: String`\n\nThe reason that we stopped.\n\nThis may be one the following values:\n\n* `\"stop_sequence\"`: we reached a stop sequence â€” either provided by you via the `stop_sequences` parameter, or a stop sequence built into the model\n    * `\"max_tokens\"`: we exceeded `max_tokens_to_sample` or the model's maximum\n\n- `type: :completion`\n\nFor Text Completions, this is always `\"completion\"`.",
  "code_samples": [
    {
      "code": "\"\n  \n  Human: {userQuestion}\n  \n  Assistant:\"",
      "language": "unknown"
    },
    {
      "code": "require \"anthropic\"\n\nanthropic = Anthropic::Client.new(api_key: \"my-anthropic-api-key\")\n\ncompletion = anthropic.completions.create(\n  max_tokens_to_sample: 256,\n  model: :\"claude-opus-4-5-20251101\",\n  prompt: \"\\n\\nHuman: Hello, world!\\n\\nAssistant:\"\n)\n\nputs(completion)",
      "language": "ruby"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Create",
      "id": "create"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Returns",
      "id": "returns"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    }
  ],
  "url": "llms-txt#create-a-text-completion-(ruby)",
  "links": []
}