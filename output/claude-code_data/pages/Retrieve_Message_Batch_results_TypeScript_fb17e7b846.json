{
  "title": "Retrieve Message Batch results (TypeScript)",
  "content": "URL: https://platform.claude.com/docs/en/api/typescript/messages/batches/results\n\n`client.messages.batches.results(stringmessageBatchID, RequestOptionsoptions?): MessageBatchIndividualResponse | Stream<MessageBatchIndividualResponse>`\n\n**get** `/v1/messages/batches/{message_batch_id}/results`\n\nStreams the results of a Message Batch as a `.jsonl` file.\n\nEach line in the file is a JSON object containing the result of a single request in the Message Batch. Results are not guaranteed to be in the same order as requests. Use the `custom_id` field to match results to requests.\n\nLearn more about the Message Batches API in our [user guide](https://docs.claude.com/en/docs/build-with-claude/batch-processing)\n\n- `messageBatchID: string`\n\nID of the Message Batch.\n\n- `MessageBatchIndividualResponse`\n\nThis is a single line in the response `.jsonl` file and does not represent the response as a whole.\n\n- `custom_id: string`\n\nDeveloper-provided ID created for each request in a Message Batch. Useful for matching results to requests, as results may be given out of request order.\n\nMust be unique for each request within the Message Batch.\n\n- `result: MessageBatchResult`\n\nProcessing result for this request.\n\nContains a Message output if processing was successful, an error response if processing failed, or the reason why processing was not attempted, such as cancellation or expiration.\n\n- `MessageBatchSucceededResult`\n\nUnique object identifier.\n\nThe format and length of IDs may change over time.\n\n- `content: Array<ContentBlock>`\n\nContent generated by the model.\n\nThis is an array of content blocks, each of which has a `type` that determines its shape.\n\nIf the request input `messages` ended with an `assistant` turn, then the response `content` will continue directly from that last turn. You can use this to constrain the model's output.\n\nFor example, if the input `messages` were:\n\nThen the response `content` might be:\n\n- `citations: Array<TextCitation> | null`\n\nCitations supporting the text block.\n\nThe type of citation returned will depend on the type of document being cited. Citing a PDF results in `page_location`, plain text results in `char_location`, and content document results in `content_block_location`.\n\n- `CitationCharLocation`\n\n- `cited_text: string`\n\n- `document_index: number`\n\n- `document_title: string | null`\n\n- `end_char_index: number`\n\n- `file_id: string | null`\n\n- `start_char_index: number`\n\n- `type: \"char_location\"`\n\n- `CitationPageLocation`\n\n- `cited_text: string`\n\n- `document_index: number`\n\n- `document_title: string | null`\n\n- `end_page_number: number`\n\n- `file_id: string | null`\n\n- `start_page_number: number`\n\n- `type: \"page_location\"`\n\n- `CitationContentBlockLocation`\n\n- `cited_text: string`\n\n- `document_index: number`\n\n- `document_title: string | null`\n\n- `end_block_index: number`\n\n- `file_id: string | null`\n\n- `start_block_index: number`\n\n- `type: \"content_block_location\"`\n\n- `\"content_block_location\"`\n\n- `CitationsWebSearchResultLocation`\n\n- `cited_text: string`\n\n- `encrypted_index: string`\n\n- `title: string | null`\n\n- `type: \"web_search_result_location\"`\n\n- `\"web_search_result_location\"`\n\n- `CitationsSearchResultLocation`\n\n- `cited_text: string`\n\n- `end_block_index: number`\n\n- `search_result_index: number`\n\n- `start_block_index: number`\n\n- `title: string | null`\n\n- `type: \"search_result_location\"`\n\n- `\"search_result_location\"`\n\n- `signature: string`\n\n- `RedactedThinkingBlock`\n\n- `type: \"redacted_thinking\"`\n\n- `\"redacted_thinking\"`\n\n- `input: Record<string, unknown>`\n\n- `ServerToolUseBlock`\n\n- `input: Record<string, unknown>`\n\n- `name: \"web_search\"`\n\n- `type: \"server_tool_use\"`\n\n- `\"server_tool_use\"`\n\n- `WebSearchToolResultBlock`\n\n- `content: WebSearchToolResultBlockContent`\n\n- `WebSearchToolResultError`\n\n- `error_code: \"invalid_tool_input\" | \"unavailable\" | \"max_uses_exceeded\" | 2 more`\n\n- `\"invalid_tool_input\"`\n\n- `\"max_uses_exceeded\"`\n\n- `\"too_many_requests\"`\n\n- `type: \"web_search_tool_result_error\"`\n\n- `\"web_search_tool_result_error\"`\n\n- `Array<WebSearchResultBlock>`\n\n- `encrypted_content: string`\n\n- `page_age: string | null`\n\n- `type: \"web_search_result\"`\n\n- `\"web_search_result\"`\n\n- `tool_use_id: string`\n\n- `type: \"web_search_tool_result\"`\n\n- `\"web_search_tool_result\"`\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `\"claude-opus-4-5-20251101\" | \"claude-opus-4-5\" | \"claude-3-7-sonnet-latest\" | 17 more`\n\n- `\"claude-opus-4-5-20251101\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `\"claude-opus-4-5\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `\"claude-3-7-sonnet-latest\"`\n\nHigh-performance model with early extended thinking\n\n- `\"claude-3-7-sonnet-20250219\"`\n\nHigh-performance model with early extended thinking\n\n- `\"claude-3-5-haiku-latest\"`\n\nFastest and most compact model for near-instant responsiveness\n\n- `\"claude-3-5-haiku-20241022\"`\n\n- `\"claude-haiku-4-5\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `\"claude-haiku-4-5-20251001\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `\"claude-sonnet-4-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `\"claude-sonnet-4-0\"`\n\nHigh-performance model with extended thinking\n\n- `\"claude-4-sonnet-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `\"claude-sonnet-4-5\"`\n\nOur best model for real-world agents and coding\n\n- `\"claude-sonnet-4-5-20250929\"`\n\nOur best model for real-world agents and coding\n\n- `\"claude-opus-4-0\"`\n\nOur most capable model\n\n- `\"claude-opus-4-20250514\"`\n\nOur most capable model\n\n- `\"claude-4-opus-20250514\"`\n\nOur most capable model\n\n- `\"claude-opus-4-1-20250805\"`\n\nOur most capable model\n\n- `\"claude-3-opus-latest\"`\n\nExcels at writing and complex tasks\n\n- `\"claude-3-opus-20240229\"`\n\nExcels at writing and complex tasks\n\n- `\"claude-3-haiku-20240307\"`\n\nOur previous most fast and cost-effective\n\n- `role: \"assistant\"`\n\nConversational role of the generated message.\n\nThis will always be `\"assistant\"`.\n\n- `stop_reason: StopReason | null`\n\nThe reason that we stopped.\n\nThis may be one the following values:\n\n* `\"end_turn\"`: the model reached a natural stopping point\n          * `\"max_tokens\"`: we exceeded the requested `max_tokens` or the model's maximum\n          * `\"stop_sequence\"`: one of your provided custom `stop_sequences` was generated\n          * `\"tool_use\"`: the model invoked one or more tools\n          * `\"pause_turn\"`: we paused a long-running turn. You may provide the response back as-is in a subsequent request to let the model continue.\n          * `\"refusal\"`: when streaming classifiers intervene to handle potential policy violations\n\nIn non-streaming mode this value is always non-null. In streaming mode, it is null in the `message_start` event and non-null otherwise.\n\n- `stop_sequence: string | null`\n\nWhich custom stop sequence was generated, if any.\n\nThis value will be a non-null string if one of your custom stop sequences was generated.\n\nFor Messages, this is always `\"message\"`.\n\nBilling and rate-limit usage.\n\nAnthropic's API bills and rate-limits by token counts, as tokens represent the underlying cost to our systems.\n\nUnder the hood, the API transforms requests into a format suitable for the model. The model's output then goes through a parsing stage before becoming an API response. As a result, the token counts in `usage` will not match one-to-one with the exact visible content of an API request or response.\n\nFor example, `output_tokens` will be non-zero, even for an empty string response from Claude.\n\nTotal input tokens in a request is the summation of `input_tokens`, `cache_creation_input_tokens`, and `cache_read_input_tokens`.\n\n- `cache_creation: CacheCreation | null`\n\nBreakdown of cached tokens by TTL\n\n- `ephemeral_1h_input_tokens: number`\n\nThe number of input tokens used to create the 1 hour cache entry.\n\n- `ephemeral_5m_input_tokens: number`\n\nThe number of input tokens used to create the 5 minute cache entry.\n\n- `cache_creation_input_tokens: number | null`\n\nThe number of input tokens used to create the cache entry.\n\n- `cache_read_input_tokens: number | null`\n\nThe number of input tokens read from the cache.\n\n- `input_tokens: number`\n\nThe number of input tokens which were used.\n\n- `output_tokens: number`\n\nThe number of output tokens which were used.\n\n- `server_tool_use: ServerToolUsage | null`\n\nThe number of server tool requests.\n\n- `web_search_requests: number`\n\nThe number of web search tool requests.\n\n- `service_tier: \"standard\" | \"priority\" | \"batch\" | null`\n\nIf the request used the priority, standard, or batch tier.\n\n- `type: \"succeeded\"`\n\n- `MessageBatchErroredResult`\n\n- `error: ErrorResponse`\n\n- `error: ErrorObject`\n\n- `InvalidRequestError`\n\n- `type: \"invalid_request_error\"`\n\n- `\"invalid_request_error\"`\n\n- `AuthenticationError`\n\n- `type: \"authentication_error\"`\n\n- `\"authentication_error\"`\n\n- `type: \"billing_error\"`\n\n- `type: \"permission_error\"`\n\n- `\"permission_error\"`\n\n- `type: \"not_found_error\"`\n\n- `\"not_found_error\"`\n\n- `type: \"rate_limit_error\"`\n\n- `\"rate_limit_error\"`\n\n- `GatewayTimeoutError`\n\n- `type: \"timeout_error\"`\n\n- `type: \"api_error\"`\n\n- `type: \"overloaded_error\"`\n\n- `\"overloaded_error\"`\n\n- `request_id: string | null`\n\n- `MessageBatchCanceledResult`\n\n- `MessageBatchExpiredResult`",
  "code_samples": [
    {
      "code": "[{\"type\": \"text\", \"text\": \"Hi, I'm Claude.\"}]",
      "language": "json"
    },
    {
      "code": "[\n            {\"role\": \"user\", \"content\": \"What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun\"},\n            {\"role\": \"assistant\", \"content\": \"The best answer is (\"}\n          ]",
      "language": "json"
    },
    {
      "code": "[{\"type\": \"text\", \"text\": \"B)\"}]",
      "language": "json"
    },
    {
      "code": "import Anthropic from '@anthropic-ai/sdk';\n\nconst client = new Anthropic({\n  apiKey: process.env['ANTHROPIC_API_KEY'], // This is the default and can be omitted\n});\n\nconst messageBatchIndividualResponse = await client.messages.batches.results('message_batch_id');\n\nconsole.log(messageBatchIndividualResponse.custom_id);",
      "language": "typescript"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Results",
      "id": "results"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Returns",
      "id": "returns"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    }
  ],
  "url": "llms-txt#retrieve-message-batch-results-(typescript)",
  "links": []
}