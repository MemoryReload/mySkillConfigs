{
  "title": "Retrieve Message Batch results (Kotlin)",
  "content": "URL: https://platform.claude.com/docs/en/api/kotlin/messages/batches/results\n\n`messages().batches().resultsStreaming(BatchResultsParamsparams = BatchResultsParams.none(), RequestOptionsrequestOptions = RequestOptions.none()) : MessageBatchIndividualResponse`\n\n**get** `/v1/messages/batches/{message_batch_id}/results`\n\nStreams the results of a Message Batch as a `.jsonl` file.\n\nEach line in the file is a JSON object containing the result of a single request in the Message Batch. Results are not guaranteed to be in the same order as requests. Use the `custom_id` field to match results to requests.\n\nLearn more about the Message Batches API in our [user guide](https://docs.claude.com/en/docs/build-with-claude/batch-processing)\n\n- `params: BatchResultsParams`\n\n- `messageBatchId: Optional<String>`\n\nID of the Message Batch.\n\n- `class MessageBatchIndividualResponse:`\n\nThis is a single line in the response `.jsonl` file and does not represent the response as a whole.\n\nDeveloper-provided ID created for each request in a Message Batch. Useful for matching results to requests, as results may be given out of request order.\n\nMust be unique for each request within the Message Batch.\n\n- `result: MessageBatchResult`\n\nProcessing result for this request.\n\nContains a Message output if processing was successful, an error response if processing failed, or the reason why processing was not attempted, such as cancellation or expiration.\n\n- `class MessageBatchSucceededResult:`\n\nUnique object identifier.\n\nThe format and length of IDs may change over time.\n\n- `content: List<ContentBlock>`\n\nContent generated by the model.\n\nThis is an array of content blocks, each of which has a `type` that determines its shape.\n\nIf the request input `messages` ended with an `assistant` turn, then the response `content` will continue directly from that last turn. You can use this to constrain the model's output.\n\nFor example, if the input `messages` were:\n\nThen the response `content` might be:\n\n- `citations: Optional<List<TextCitation>>`\n\nCitations supporting the text block.\n\nThe type of citation returned will depend on the type of document being cited. Citing a PDF results in `page_location`, plain text results in `char_location`, and content document results in `content_block_location`.\n\n- `class CitationCharLocation:`\n\n- `citedText: String`\n\n- `documentIndex: Long`\n\n- `documentTitle: Optional<String>`\n\n- `endCharIndex: Long`\n\n- `fileId: Optional<String>`\n\n- `startCharIndex: Long`\n\n- `type: JsonValue; \"char_location\"constant`\n\n- `CHAR_LOCATION(\"char_location\")`\n\n- `class CitationPageLocation:`\n\n- `citedText: String`\n\n- `documentIndex: Long`\n\n- `documentTitle: Optional<String>`\n\n- `endPageNumber: Long`\n\n- `fileId: Optional<String>`\n\n- `startPageNumber: Long`\n\n- `type: JsonValue; \"page_location\"constant`\n\n- `PAGE_LOCATION(\"page_location\")`\n\n- `class CitationContentBlockLocation:`\n\n- `citedText: String`\n\n- `documentIndex: Long`\n\n- `documentTitle: Optional<String>`\n\n- `endBlockIndex: Long`\n\n- `fileId: Optional<String>`\n\n- `startBlockIndex: Long`\n\n- `type: JsonValue; \"content_block_location\"constant`\n\n- `CONTENT_BLOCK_LOCATION(\"content_block_location\")`\n\n- `class CitationsWebSearchResultLocation:`\n\n- `citedText: String`\n\n- `encryptedIndex: String`\n\n- `title: Optional<String>`\n\n- `type: JsonValue; \"web_search_result_location\"constant`\n\n- `WEB_SEARCH_RESULT_LOCATION(\"web_search_result_location\")`\n\n- `class CitationsSearchResultLocation:`\n\n- `citedText: String`\n\n- `endBlockIndex: Long`\n\n- `searchResultIndex: Long`\n\n- `startBlockIndex: Long`\n\n- `title: Optional<String>`\n\n- `type: JsonValue; \"search_result_location\"constant`\n\n- `SEARCH_RESULT_LOCATION(\"search_result_location\")`\n\n- `type: JsonValue; \"text\"constant`\n\n- `class ThinkingBlock:`\n\n- `signature: String`\n\n- `type: JsonValue; \"thinking\"constant`\n\n- `THINKING(\"thinking\")`\n\n- `class RedactedThinkingBlock:`\n\n- `type: JsonValue; \"redacted_thinking\"constant`\n\n- `REDACTED_THINKING(\"redacted_thinking\")`\n\n- `class ToolUseBlock:`\n\n- `type: JsonValue; \"tool_use\"constant`\n\n- `TOOL_USE(\"tool_use\")`\n\n- `class ServerToolUseBlock:`\n\n- `name: JsonValue; \"web_search\"constant`\n\n- `WEB_SEARCH(\"web_search\")`\n\n- `type: JsonValue; \"server_tool_use\"constant`\n\n- `SERVER_TOOL_USE(\"server_tool_use\")`\n\n- `class WebSearchToolResultBlock:`\n\n- `content: WebSearchToolResultBlockContent`\n\n- `class WebSearchToolResultError:`\n\n- `errorCode: ErrorCode`\n\n- `INVALID_TOOL_INPUT(\"invalid_tool_input\")`\n\n- `UNAVAILABLE(\"unavailable\")`\n\n- `MAX_USES_EXCEEDED(\"max_uses_exceeded\")`\n\n- `TOO_MANY_REQUESTS(\"too_many_requests\")`\n\n- `QUERY_TOO_LONG(\"query_too_long\")`\n\n- `type: JsonValue; \"web_search_tool_result_error\"constant`\n\n- `WEB_SEARCH_TOOL_RESULT_ERROR(\"web_search_tool_result_error\")`\n\n- `List<WebSearchResultBlock>`\n\n- `encryptedContent: String`\n\n- `pageAge: Optional<String>`\n\n- `type: JsonValue; \"web_search_result\"constant`\n\n- `WEB_SEARCH_RESULT(\"web_search_result\")`\n\n- `toolUseId: String`\n\n- `type: JsonValue; \"web_search_tool_result\"constant`\n\n- `WEB_SEARCH_TOOL_RESULT(\"web_search_tool_result\")`\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `CLAUDE_OPUS_4_5_20251101(\"claude-opus-4-5-20251101\")`\n\nPremium model combining maximum intelligence with practical performance\n\n- `CLAUDE_OPUS_4_5(\"claude-opus-4-5\")`\n\nPremium model combining maximum intelligence with practical performance\n\n- `CLAUDE_3_7_SONNET_LATEST(\"claude-3-7-sonnet-latest\")`\n\nHigh-performance model with early extended thinking\n\n- `CLAUDE_3_7_SONNET_20250219(\"claude-3-7-sonnet-20250219\")`\n\nHigh-performance model with early extended thinking\n\n- `CLAUDE_3_5_HAIKU_LATEST(\"claude-3-5-haiku-latest\")`\n\nFastest and most compact model for near-instant responsiveness\n\n- `CLAUDE_3_5_HAIKU_20241022(\"claude-3-5-haiku-20241022\")`\n\n- `CLAUDE_HAIKU_4_5(\"claude-haiku-4-5\")`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `CLAUDE_HAIKU_4_5_20251001(\"claude-haiku-4-5-20251001\")`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `CLAUDE_SONNET_4_20250514(\"claude-sonnet-4-20250514\")`\n\nHigh-performance model with extended thinking\n\n- `CLAUDE_SONNET_4_0(\"claude-sonnet-4-0\")`\n\nHigh-performance model with extended thinking\n\n- `CLAUDE_4_SONNET_20250514(\"claude-4-sonnet-20250514\")`\n\nHigh-performance model with extended thinking\n\n- `CLAUDE_SONNET_4_5(\"claude-sonnet-4-5\")`\n\nOur best model for real-world agents and coding\n\n- `CLAUDE_SONNET_4_5_20250929(\"claude-sonnet-4-5-20250929\")`\n\nOur best model for real-world agents and coding\n\n- `CLAUDE_OPUS_4_0(\"claude-opus-4-0\")`\n\nOur most capable model\n\n- `CLAUDE_OPUS_4_20250514(\"claude-opus-4-20250514\")`\n\nOur most capable model\n\n- `CLAUDE_4_OPUS_20250514(\"claude-4-opus-20250514\")`\n\nOur most capable model\n\n- `CLAUDE_OPUS_4_1_20250805(\"claude-opus-4-1-20250805\")`\n\nOur most capable model\n\n- `CLAUDE_3_OPUS_LATEST(\"claude-3-opus-latest\")`\n\nExcels at writing and complex tasks\n\n- `CLAUDE_3_OPUS_20240229(\"claude-3-opus-20240229\")`\n\nExcels at writing and complex tasks\n\n- `CLAUDE_3_HAIKU_20240307(\"claude-3-haiku-20240307\")`\n\nOur previous most fast and cost-effective\n\n- `role: JsonValue; \"assistant\"constant`\n\nConversational role of the generated message.\n\nThis will always be `\"assistant\"`.\n\n- `ASSISTANT(\"assistant\")`\n\n- `stopReason: Optional<StopReason>`\n\nThe reason that we stopped.\n\nThis may be one the following values:\n\n* `\"end_turn\"`: the model reached a natural stopping point\n          * `\"max_tokens\"`: we exceeded the requested `max_tokens` or the model's maximum\n          * `\"stop_sequence\"`: one of your provided custom `stop_sequences` was generated\n          * `\"tool_use\"`: the model invoked one or more tools\n          * `\"pause_turn\"`: we paused a long-running turn. You may provide the response back as-is in a subsequent request to let the model continue.\n          * `\"refusal\"`: when streaming classifiers intervene to handle potential policy violations\n\nIn non-streaming mode this value is always non-null. In streaming mode, it is null in the `message_start` event and non-null otherwise.\n\n- `END_TURN(\"end_turn\")`\n\n- `MAX_TOKENS(\"max_tokens\")`\n\n- `STOP_SEQUENCE(\"stop_sequence\")`\n\n- `TOOL_USE(\"tool_use\")`\n\n- `PAUSE_TURN(\"pause_turn\")`\n\n- `REFUSAL(\"refusal\")`\n\n- `stopSequence: Optional<String>`\n\nWhich custom stop sequence was generated, if any.\n\nThis value will be a non-null string if one of your custom stop sequences was generated.\n\n- `type: JsonValue; \"message\"constant`\n\nFor Messages, this is always `\"message\"`.\n\n- `MESSAGE(\"message\")`\n\nBilling and rate-limit usage.\n\nAnthropic's API bills and rate-limits by token counts, as tokens represent the underlying cost to our systems.\n\nUnder the hood, the API transforms requests into a format suitable for the model. The model's output then goes through a parsing stage before becoming an API response. As a result, the token counts in `usage` will not match one-to-one with the exact visible content of an API request or response.\n\nFor example, `output_tokens` will be non-zero, even for an empty string response from Claude.\n\nTotal input tokens in a request is the summation of `input_tokens`, `cache_creation_input_tokens`, and `cache_read_input_tokens`.\n\n- `cacheCreation: Optional<CacheCreation>`\n\nBreakdown of cached tokens by TTL\n\n- `ephemeral1hInputTokens: Long`\n\nThe number of input tokens used to create the 1 hour cache entry.\n\n- `ephemeral5mInputTokens: Long`\n\nThe number of input tokens used to create the 5 minute cache entry.\n\n- `cacheCreationInputTokens: Optional<Long>`\n\nThe number of input tokens used to create the cache entry.\n\n- `cacheReadInputTokens: Optional<Long>`\n\nThe number of input tokens read from the cache.\n\n- `inputTokens: Long`\n\nThe number of input tokens which were used.\n\n- `outputTokens: Long`\n\nThe number of output tokens which were used.\n\n- `serverToolUse: Optional<ServerToolUsage>`\n\nThe number of server tool requests.\n\n- `webSearchRequests: Long`\n\nThe number of web search tool requests.\n\n- `serviceTier: Optional<ServiceTier>`\n\nIf the request used the priority, standard, or batch tier.\n\n- `STANDARD(\"standard\")`\n\n- `PRIORITY(\"priority\")`\n\n- `type: JsonValue; \"succeeded\"constant`\n\n- `SUCCEEDED(\"succeeded\")`\n\n- `class MessageBatchErroredResult:`\n\n- `error: ErrorResponse`\n\n- `error: ErrorObject`\n\n- `class InvalidRequestError:`\n\n- `type: JsonValue; \"invalid_request_error\"constant`\n\n- `INVALID_REQUEST_ERROR(\"invalid_request_error\")`\n\n- `class AuthenticationError:`\n\n- `type: JsonValue; \"authentication_error\"constant`\n\n- `AUTHENTICATION_ERROR(\"authentication_error\")`\n\n- `class BillingError:`\n\n- `type: JsonValue; \"billing_error\"constant`\n\n- `BILLING_ERROR(\"billing_error\")`\n\n- `class PermissionError:`\n\n- `type: JsonValue; \"permission_error\"constant`\n\n- `PERMISSION_ERROR(\"permission_error\")`\n\n- `class NotFoundError:`\n\n- `type: JsonValue; \"not_found_error\"constant`\n\n- `NOT_FOUND_ERROR(\"not_found_error\")`\n\n- `class RateLimitError:`\n\n- `type: JsonValue; \"rate_limit_error\"constant`\n\n- `RATE_LIMIT_ERROR(\"rate_limit_error\")`\n\n- `class GatewayTimeoutError:`\n\n- `type: JsonValue; \"timeout_error\"constant`\n\n- `TIMEOUT_ERROR(\"timeout_error\")`\n\n- `class ApiErrorObject:`\n\n- `type: JsonValue; \"api_error\"constant`\n\n- `API_ERROR(\"api_error\")`\n\n- `class OverloadedError:`\n\n- `type: JsonValue; \"overloaded_error\"constant`\n\n- `OVERLOADED_ERROR(\"overloaded_error\")`\n\n- `requestId: Optional<String>`\n\n- `type: JsonValue; \"error\"constant`\n\n- `type: JsonValue; \"errored\"constant`\n\n- `ERRORED(\"errored\")`\n\n- `class MessageBatchCanceledResult:`\n\n- `type: JsonValue; \"canceled\"constant`\n\n- `CANCELED(\"canceled\")`\n\n- `class MessageBatchExpiredResult:`\n\n- `type: JsonValue; \"expired\"constant`\n\n- `EXPIRED(\"expired\")`",
  "code_samples": [
    {
      "code": "[{\"type\": \"text\", \"text\": \"Hi, I'm Claude.\"}]",
      "language": "json"
    },
    {
      "code": "[\n            {\"role\": \"user\", \"content\": \"What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun\"},\n            {\"role\": \"assistant\", \"content\": \"The best answer is (\"}\n          ]",
      "language": "json"
    },
    {
      "code": "[{\"type\": \"text\", \"text\": \"B)\"}]",
      "language": "json"
    },
    {
      "code": "package com.anthropic.example\n\nimport com.anthropic.client.AnthropicClient\nimport com.anthropic.client.okhttp.AnthropicOkHttpClient\nimport com.anthropic.core.http.StreamResponse\nimport com.anthropic.models.messages.batches.BatchResultsParams\nimport com.anthropic.models.messages.batches.MessageBatchIndividualResponse\n\nfun main() {\n    val client: AnthropicClient = AnthropicOkHttpClient.fromEnv()\n\n    val messageBatchIndividualResponse: StreamResponse<MessageBatchIndividualResponse> = client.messages().batches().resultsStreaming(\"message_batch_id\")\n}",
      "language": "kotlin"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Results",
      "id": "results"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Returns",
      "id": "returns"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    }
  ],
  "url": "llms-txt#retrieve-message-batch-results-(kotlin)",
  "links": []
}