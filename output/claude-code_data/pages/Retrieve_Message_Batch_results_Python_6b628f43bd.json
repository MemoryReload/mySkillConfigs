{
  "title": "Retrieve Message Batch results (Python)",
  "content": "URL: https://platform.claude.com/docs/en/api/python/messages/batches/results\n\n`messages.batches.results(strmessage_batch_id)  -> MessageBatchIndividualResponse`\n\n**get** `/v1/messages/batches/{message_batch_id}/results`\n\nStreams the results of a Message Batch as a `.jsonl` file.\n\nEach line in the file is a JSON object containing the result of a single request in the Message Batch. Results are not guaranteed to be in the same order as requests. Use the `custom_id` field to match results to requests.\n\nLearn more about the Message Batches API in our [user guide](https://docs.claude.com/en/docs/build-with-claude/batch-processing)\n\n- `message_batch_id: str`\n\nID of the Message Batch.\n\n- `class MessageBatchIndividualResponse: …`\n\nThis is a single line in the response `.jsonl` file and does not represent the response as a whole.\n\nDeveloper-provided ID created for each request in a Message Batch. Useful for matching results to requests, as results may be given out of request order.\n\nMust be unique for each request within the Message Batch.\n\n- `result: MessageBatchResult`\n\nProcessing result for this request.\n\nContains a Message output if processing was successful, an error response if processing failed, or the reason why processing was not attempted, such as cancellation or expiration.\n\n- `class MessageBatchSucceededResult: …`\n\nUnique object identifier.\n\nThe format and length of IDs may change over time.\n\n- `content: List[ContentBlock]`\n\nContent generated by the model.\n\nThis is an array of content blocks, each of which has a `type` that determines its shape.\n\nIf the request input `messages` ended with an `assistant` turn, then the response `content` will continue directly from that last turn. You can use this to constrain the model's output.\n\nFor example, if the input `messages` were:\n\nThen the response `content` might be:\n\n- `class TextBlock: …`\n\n- `citations: Optional[List[TextCitation]]`\n\nCitations supporting the text block.\n\nThe type of citation returned will depend on the type of document being cited. Citing a PDF results in `page_location`, plain text results in `char_location`, and content document results in `content_block_location`.\n\n- `class CitationCharLocation: …`\n\n- `document_index: int`\n\n- `document_title: Optional[str]`\n\n- `end_char_index: int`\n\n- `file_id: Optional[str]`\n\n- `start_char_index: int`\n\n- `type: Literal[\"char_location\"]`\n\n- `class CitationPageLocation: …`\n\n- `document_index: int`\n\n- `document_title: Optional[str]`\n\n- `end_page_number: int`\n\n- `file_id: Optional[str]`\n\n- `start_page_number: int`\n\n- `type: Literal[\"page_location\"]`\n\n- `class CitationContentBlockLocation: …`\n\n- `document_index: int`\n\n- `document_title: Optional[str]`\n\n- `end_block_index: int`\n\n- `file_id: Optional[str]`\n\n- `start_block_index: int`\n\n- `type: Literal[\"content_block_location\"]`\n\n- `\"content_block_location\"`\n\n- `class CitationsWebSearchResultLocation: …`\n\n- `encrypted_index: str`\n\n- `title: Optional[str]`\n\n- `type: Literal[\"web_search_result_location\"]`\n\n- `\"web_search_result_location\"`\n\n- `class CitationsSearchResultLocation: …`\n\n- `end_block_index: int`\n\n- `search_result_index: int`\n\n- `start_block_index: int`\n\n- `title: Optional[str]`\n\n- `type: Literal[\"search_result_location\"]`\n\n- `\"search_result_location\"`\n\n- `type: Literal[\"text\"]`\n\n- `class ThinkingBlock: …`\n\n- `type: Literal[\"thinking\"]`\n\n- `class RedactedThinkingBlock: …`\n\n- `type: Literal[\"redacted_thinking\"]`\n\n- `\"redacted_thinking\"`\n\n- `class ToolUseBlock: …`\n\n- `input: Dict[str, object]`\n\n- `type: Literal[\"tool_use\"]`\n\n- `class ServerToolUseBlock: …`\n\n- `input: Dict[str, object]`\n\n- `name: Literal[\"web_search\"]`\n\n- `type: Literal[\"server_tool_use\"]`\n\n- `\"server_tool_use\"`\n\n- `class WebSearchToolResultBlock: …`\n\n- `content: WebSearchToolResultBlockContent`\n\n- `class WebSearchToolResultError: …`\n\n- `error_code: Literal[\"invalid_tool_input\", \"unavailable\", \"max_uses_exceeded\", 2 more]`\n\n- `\"invalid_tool_input\"`\n\n- `\"max_uses_exceeded\"`\n\n- `\"too_many_requests\"`\n\n- `type: Literal[\"web_search_tool_result_error\"]`\n\n- `\"web_search_tool_result_error\"`\n\n- `UnionMember1 = List[WebSearchResultBlock]`\n\n- `encrypted_content: str`\n\n- `page_age: Optional[str]`\n\n- `type: Literal[\"web_search_result\"]`\n\n- `\"web_search_result\"`\n\n- `type: Literal[\"web_search_tool_result\"]`\n\n- `\"web_search_tool_result\"`\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `UnionMember0 = Literal[\"claude-opus-4-5-20251101\", \"claude-opus-4-5\", \"claude-3-7-sonnet-latest\", 17 more]`\n\nThe model that will complete your prompt.\n\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.\n\n- `claude-opus-4-5-20251101` - Premium model combining maximum intelligence with practical performance\n            - `claude-opus-4-5` - Premium model combining maximum intelligence with practical performance\n            - `claude-3-7-sonnet-latest` - Deprecated: Will reach end-of-life on February 19th, 2026. Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n            - `claude-3-7-sonnet-20250219` - Deprecated: Will reach end-of-life on February 19th, 2026. Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n            - `claude-3-5-haiku-latest` - Fastest and most compact model for near-instant responsiveness\n            - `claude-3-5-haiku-20241022` - Our fastest model\n            - `claude-haiku-4-5` - Hybrid model, capable of near-instant responses and extended thinking\n            - `claude-haiku-4-5-20251001` - Hybrid model, capable of near-instant responses and extended thinking\n            - `claude-sonnet-4-20250514` - High-performance model with extended thinking\n            - `claude-sonnet-4-0` - High-performance model with extended thinking\n            - `claude-4-sonnet-20250514` - High-performance model with extended thinking\n            - `claude-sonnet-4-5` - Our best model for real-world agents and coding\n            - `claude-sonnet-4-5-20250929` - Our best model for real-world agents and coding\n            - `claude-opus-4-0` - Our most capable model\n            - `claude-opus-4-20250514` - Our most capable model\n            - `claude-4-opus-20250514` - Our most capable model\n            - `claude-opus-4-1-20250805` - Our most capable model\n            - `claude-3-opus-latest` - Deprecated: Will reach end-of-life on January 5th, 2026. Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n            - `claude-3-opus-20240229` - Deprecated: Will reach end-of-life on January 5th, 2026. Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n            - `claude-3-haiku-20240307` - Our previous most fast and cost-effective\n\n- `\"claude-opus-4-5-20251101\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `\"claude-opus-4-5\"`\n\nPremium model combining maximum intelligence with practical performance\n\n- `\"claude-3-7-sonnet-latest\"`\n\nHigh-performance model with early extended thinking\n\n- `\"claude-3-7-sonnet-20250219\"`\n\nHigh-performance model with early extended thinking\n\n- `\"claude-3-5-haiku-latest\"`\n\nFastest and most compact model for near-instant responsiveness\n\n- `\"claude-3-5-haiku-20241022\"`\n\n- `\"claude-haiku-4-5\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `\"claude-haiku-4-5-20251001\"`\n\nHybrid model, capable of near-instant responses and extended thinking\n\n- `\"claude-sonnet-4-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `\"claude-sonnet-4-0\"`\n\nHigh-performance model with extended thinking\n\n- `\"claude-4-sonnet-20250514\"`\n\nHigh-performance model with extended thinking\n\n- `\"claude-sonnet-4-5\"`\n\nOur best model for real-world agents and coding\n\n- `\"claude-sonnet-4-5-20250929\"`\n\nOur best model for real-world agents and coding\n\n- `\"claude-opus-4-0\"`\n\nOur most capable model\n\n- `\"claude-opus-4-20250514\"`\n\nOur most capable model\n\n- `\"claude-4-opus-20250514\"`\n\nOur most capable model\n\n- `\"claude-opus-4-1-20250805\"`\n\nOur most capable model\n\n- `\"claude-3-opus-latest\"`\n\nExcels at writing and complex tasks\n\n- `\"claude-3-opus-20240229\"`\n\nExcels at writing and complex tasks\n\n- `\"claude-3-haiku-20240307\"`\n\nOur previous most fast and cost-effective\n\n- `UnionMember1 = str`\n\n- `role: Literal[\"assistant\"]`\n\nConversational role of the generated message.\n\nThis will always be `\"assistant\"`.\n\n- `stop_reason: Optional[StopReason]`\n\nThe reason that we stopped.\n\nThis may be one the following values:\n\n* `\"end_turn\"`: the model reached a natural stopping point\n          * `\"max_tokens\"`: we exceeded the requested `max_tokens` or the model's maximum\n          * `\"stop_sequence\"`: one of your provided custom `stop_sequences` was generated\n          * `\"tool_use\"`: the model invoked one or more tools\n          * `\"pause_turn\"`: we paused a long-running turn. You may provide the response back as-is in a subsequent request to let the model continue.\n          * `\"refusal\"`: when streaming classifiers intervene to handle potential policy violations\n\nIn non-streaming mode this value is always non-null. In streaming mode, it is null in the `message_start` event and non-null otherwise.\n\n- `stop_sequence: Optional[str]`\n\nWhich custom stop sequence was generated, if any.\n\nThis value will be a non-null string if one of your custom stop sequences was generated.\n\n- `type: Literal[\"message\"]`\n\nFor Messages, this is always `\"message\"`.\n\nBilling and rate-limit usage.\n\nAnthropic's API bills and rate-limits by token counts, as tokens represent the underlying cost to our systems.\n\nUnder the hood, the API transforms requests into a format suitable for the model. The model's output then goes through a parsing stage before becoming an API response. As a result, the token counts in `usage` will not match one-to-one with the exact visible content of an API request or response.\n\nFor example, `output_tokens` will be non-zero, even for an empty string response from Claude.\n\nTotal input tokens in a request is the summation of `input_tokens`, `cache_creation_input_tokens`, and `cache_read_input_tokens`.\n\n- `cache_creation: Optional[CacheCreation]`\n\nBreakdown of cached tokens by TTL\n\n- `ephemeral_1h_input_tokens: int`\n\nThe number of input tokens used to create the 1 hour cache entry.\n\n- `ephemeral_5m_input_tokens: int`\n\nThe number of input tokens used to create the 5 minute cache entry.\n\n- `cache_creation_input_tokens: Optional[int]`\n\nThe number of input tokens used to create the cache entry.\n\n- `cache_read_input_tokens: Optional[int]`\n\nThe number of input tokens read from the cache.\n\n- `input_tokens: int`\n\nThe number of input tokens which were used.\n\n- `output_tokens: int`\n\nThe number of output tokens which were used.\n\n- `server_tool_use: Optional[ServerToolUsage]`\n\nThe number of server tool requests.\n\n- `web_search_requests: int`\n\nThe number of web search tool requests.\n\n- `service_tier: Optional[Literal[\"standard\", \"priority\", \"batch\"]]`\n\nIf the request used the priority, standard, or batch tier.\n\n- `type: Literal[\"succeeded\"]`\n\n- `class MessageBatchErroredResult: …`\n\n- `error: ErrorResponse`\n\n- `error: ErrorObject`\n\n- `class InvalidRequestError: …`\n\n- `type: Literal[\"invalid_request_error\"]`\n\n- `\"invalid_request_error\"`\n\n- `class AuthenticationError: …`\n\n- `type: Literal[\"authentication_error\"]`\n\n- `\"authentication_error\"`\n\n- `class BillingError: …`\n\n- `type: Literal[\"billing_error\"]`\n\n- `class PermissionError: …`\n\n- `type: Literal[\"permission_error\"]`\n\n- `\"permission_error\"`\n\n- `class NotFoundError: …`\n\n- `type: Literal[\"not_found_error\"]`\n\n- `\"not_found_error\"`\n\n- `class RateLimitError: …`\n\n- `type: Literal[\"rate_limit_error\"]`\n\n- `\"rate_limit_error\"`\n\n- `class GatewayTimeoutError: …`\n\n- `type: Literal[\"timeout_error\"]`\n\n- `class APIErrorObject: …`\n\n- `type: Literal[\"api_error\"]`\n\n- `class OverloadedError: …`\n\n- `type: Literal[\"overloaded_error\"]`\n\n- `\"overloaded_error\"`\n\n- `request_id: Optional[str]`\n\n- `type: Literal[\"error\"]`\n\n- `type: Literal[\"errored\"]`\n\n- `class MessageBatchCanceledResult: …`\n\n- `type: Literal[\"canceled\"]`\n\n- `class MessageBatchExpiredResult: …`\n\n- `type: Literal[\"expired\"]`",
  "code_samples": [
    {
      "code": "[{\"type\": \"text\", \"text\": \"Hi, I'm Claude.\"}]",
      "language": "json"
    },
    {
      "code": "[\n            {\"role\": \"user\", \"content\": \"What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun\"},\n            {\"role\": \"assistant\", \"content\": \"The best answer is (\"}\n          ]",
      "language": "json"
    },
    {
      "code": "[{\"type\": \"text\", \"text\": \"B)\"}]",
      "language": "json"
    },
    {
      "code": "import os\nfrom anthropic import Anthropic\n\nclient = Anthropic(\n    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),  # This is the default and can be omitted\n)\nmessage_batch_individual_response = client.messages.batches.results(\n    \"message_batch_id\",\n)\nprint(message_batch_individual_response.custom_id)",
      "language": "python"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Results",
      "id": "results"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Returns",
      "id": "returns"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    }
  ],
  "url": "llms-txt#retrieve-message-batch-results-(python)",
  "links": []
}